{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate localization strategies\n",
    "\n",
    "This notebook does a comparative evaluation of different localization strategies.\n",
    "- Defines a base interface for localization\n",
    "- Implements a few localization strategies\n",
    "- Defines an evaluator the runs a test suite on those localization strategies\n",
    "- Evaluator dumps the results in a pandas dataframe\n",
    "- Uses Milvus as the vector database\n",
    "- Uses OpenAI's embeddings model\n",
    "- Uses langchain's abstractions for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple\n",
    "from abc import ABC, abstractmethod\n",
    "from langchain_core.documents import Document\n",
    "from langchain_milvus import Milvus\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base interface for localization strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Strategy(ABC):\n",
    "    @abstractmethod\n",
    "    def localize(self, issue: Dict[str, str], top_n: int) -> List[Tuple[str, str]]:\n",
    "        \"\"\"\n",
    "        Localizes the issue to a set of relevant packages and files.\n",
    "\n",
    "        Args:\n",
    "            issue (Dict[str, str]): A dictionary containing issue details with at least:\n",
    "                - `title` (str): The title of the issue.\n",
    "                - `description` (str): The detailed description of the issue.\n",
    "            top_n (int): The maximum number of localization results to return.\n",
    "\n",
    "        Returns:\n",
    "            List[Tuple[str, str]]: A list of tuples representing relevant localization results,\n",
    "                each containing `package` (str) and `file` (str).\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic vector search strategy\n",
    "\n",
    "This implements a simple semantic vector search strategy. It uses Milvus as the vector database and OpenAI's embeddings model. Implementation may be used as-is for multiple strategies by feeding in different types of sources. E.g.,\n",
    "- **Code file embeddings**: Providing a `source_dir` pointing to code files will directly embed code\n",
    "- **Code semantics embeddings**: Providing a `source_dir` pointing to semantic descriptions of code files will embed code semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticVectorSearchStrategy(Strategy):\n",
    "    def __init__(self, source_dir: str, root_package_name: str, embeddings, strategy_name: str):\n",
    "        self.strategy_name = strategy_name\n",
    "        self.vector_store = self.create_vector_store(source_dir, root_package_name, embeddings)\n",
    "\n",
    "    def create_vector_store(self, folder_path: str, root_package_name: str, embeddings) -> Milvus:\n",
    "        \"\"\"Creates a Milvus vector store from the files in the specified folder.\"\"\"\n",
    "        documents = self.create_documents(folder_path, root_package_name)\n",
    "        with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as tmp_file:\n",
    "            uri = tmp_file.name\n",
    "        return Milvus.from_documents(\n",
    "            documents,\n",
    "            embeddings,\n",
    "            collection_name=root_package_name,\n",
    "            connection_args={\"uri\": uri},\n",
    "        )\n",
    "    \n",
    "    def create_documents(self, folder_path: str, root_package_name: str) -> List[Document]:\n",
    "        \"\"\"Create a list of Document instances from the files in the specified folder.\"\"\"\n",
    "        documents = []\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, \"r\") as f:\n",
    "                    page_content = f.read()\n",
    "                if not page_content.strip():\n",
    "                    continue\n",
    "                filename = file.split('.')[0]\n",
    "                relative_path = os.path.relpath(root, folder_path)\n",
    "                package = (f\"{root_package_name}/{relative_path.replace(os.sep, '/')}\"\n",
    "                           if relative_path != \".\" else root_package_name)\n",
    "                document = Document(\n",
    "                    page_content=page_content,\n",
    "                    metadata={\"file\": filename, \"package\": package}\n",
    "                )\n",
    "                documents.append(document)\n",
    "        return documents\n",
    "\n",
    "    def localize(self, issue: Dict[str, str], top_n: int) -> List[Tuple[str, str]]:\n",
    "        query_string = f\"{issue['title']}: {issue['description']}\"\n",
    "        results = self.vector_store.similarity_search(query_string, k=top_n)\n",
    "        return [(res.metadata[\"package\"], res.metadata[\"file\"]) for res in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalizationEvaluator:\n",
    "    def __init__(self, issues_dir: str, strategies_to_evaluate: List[Strategy]):\n",
    "        self.issues_dir = issues_dir\n",
    "        self.strategies = strategies_to_evaluate\n",
    "\n",
    "    def evaluate(self) -> pd.DataFrame:\n",
    "        \"\"\"Evaluates each strategy on all test issues and returns a DataFrame with results.\"\"\"\n",
    "        df = pd.DataFrame(columns=[\"Test case\"] + [f\"Results ({strategy.strategy_name})\" for strategy in self.strategies])\n",
    "\n",
    "        # Iterate over files in the issues directory\n",
    "        for root, _, files in os.walk(self.issues_dir):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                test_case_name = os.path.splitext(file)[0].replace('_', ' ').replace('-', ' ')\n",
    "                with open(file_path, 'r') as f:\n",
    "                    issue_content = f.read().strip()\n",
    "                issue = {\"title\": test_case_name, \"description\": issue_content}\n",
    "\n",
    "                # Collect localization results for each strategy\n",
    "                results = {}\n",
    "                for strategy in self.strategies:\n",
    "                    localization_results = strategy.localize(issue, top_n=5)\n",
    "                    results[f\"Results ({strategy.strategy_name})\"] = localization_results\n",
    "\n",
    "                # Append the data to the DataFrame\n",
    "                row_data = {\"Test case\": test_case_name, **results}\n",
    "                df = pd.concat([df, pd.DataFrame([row_data])], ignore_index=True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_store = \"/Users/pdhoolia/se-agent-projects\"\n",
    "repo_full_name = \"conversational-ai/se-agent\"\n",
    "src_dir = \"se_agent\"\n",
    "\n",
    "code_dir = os.path.join(projects_store, repo_full_name, \"repo\", src_dir)\n",
    "code_semantics_dir = os.path.join(projects_store, repo_full_name, \"metadata\", \"package_details\")\n",
    "test_issues_folder = \"test/issues\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strategies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_file_embeddings = SemanticVectorSearchStrategy(code_dir, src_dir, embeddings, strategy_name=\"Code File Embeddings\")\n",
    "code_semantics_embeddings = SemanticVectorSearchStrategy(code_semantics_dir, src_dir, embeddings, strategy_name=\"Code Semantics Embeddings\")\n",
    "\n",
    "strategies_to_evaluate = [code_file_embeddings, code_semantics_embeddings]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = LocalizationEvaluator(\n",
    "    issues_dir=test_issues_folder,\n",
    "    strategies_to_evaluate=strategies_to_evaluate\n",
    ")\n",
    "\n",
    "evaluation_results = evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1c9d6 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_1c9d6_row0_col0, #T_1c9d6_row0_col1, #T_1c9d6_row0_col2, #T_1c9d6_row1_col0, #T_1c9d6_row1_col1, #T_1c9d6_row1_col2, #T_1c9d6_row2_col0, #T_1c9d6_row2_col1, #T_1c9d6_row2_col2, #T_1c9d6_row3_col0, #T_1c9d6_row3_col1, #T_1c9d6_row3_col2, #T_1c9d6_row4_col0, #T_1c9d6_row4_col1, #T_1c9d6_row4_col2 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1c9d6\" style='width:100%'>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1c9d6_level0_col0\" class=\"col_heading level0 col0\" >Test case</th>\n",
       "      <th id=\"T_1c9d6_level0_col1\" class=\"col_heading level0 col1\" >Results (Code File Embeddings)</th>\n",
       "      <th id=\"T_1c9d6_level0_col2\" class=\"col_heading level0 col2\" >Results (Code Semantics Embeddings)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1c9d6_level0_row0\" class=\"row_heading level0 row0\" >2</th>\n",
       "      <td id=\"T_1c9d6_row0_col0\" class=\"data row0 col0\" >avoid user annoyance</td>\n",
       "      <td id=\"T_1c9d6_row0_col1\" class=\"data row0 col1\" >['project', 'issue_analyzer', 'change_suggester', 'localizer', 'onboard_agent']</td>\n",
       "      <td id=\"T_1c9d6_row0_col2\" class=\"data row0 col2\" >['issue_analyzer', 'github_listener', 'onboard_agent', 'change_suggester', 'localizer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1c9d6_level0_row1\" class=\"row_heading level0 row1\" >3</th>\n",
       "      <td id=\"T_1c9d6_row1_col0\" class=\"data row1 col0\" >structured output from semantic summar genaration task</td>\n",
       "      <td id=\"T_1c9d6_row1_col1\" class=\"data row1 col1\" >['package_summary', 'change_suggester', 'localizer', 'file_analyzer', 'project']</td>\n",
       "      <td id=\"T_1c9d6_row1_col2\" class=\"data row1 col2\" >['package_summary', 'change_suggester', 'localizer', 'file_analyzer', '__init__']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1c9d6_level0_row2\" class=\"row_heading level0 row2\" >4</th>\n",
       "      <td id=\"T_1c9d6_row2_col0\" class=\"data row2 col0\" >retry llm call on ratelimiterror</td>\n",
       "      <td id=\"T_1c9d6_row2_col1\" class=\"data row2 col1\" >['api', 'retry_with_backoff', 'localizer', 'change_suggester', 'project']</td>\n",
       "      <td id=\"T_1c9d6_row2_col2\" class=\"data row2 col2\" >['retry_with_backoff', 'api', 'localizer', 'package_summary', 'change_suggester']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1c9d6_level0_row3\" class=\"row_heading level0 row3\" >5</th>\n",
       "      <td id=\"T_1c9d6_row3_col0\" class=\"data row3 col0\" >rag for localization</td>\n",
       "      <td id=\"T_1c9d6_row3_col1\" class=\"data row3 col1\" >['localizer', 'change_suggester', 'project', 'api', 'issue_analyzer']</td>\n",
       "      <td id=\"T_1c9d6_row3_col2\" class=\"data row3 col2\" >['localizer', 'change_suggester', 'api', 'issue_analyzer', 'package_summary']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1c9d6_level0_row4\" class=\"row_heading level0 row4\" >6</th>\n",
       "      <td id=\"T_1c9d6_row4_col0\" class=\"data row4 col0\" >tool based code structure name gen</td>\n",
       "      <td id=\"T_1c9d6_row4_col1\" class=\"data row4 col1\" >['package_summary', 'change_suggester', 'file_analyzer', 'localizer', 'project']</td>\n",
       "      <td id=\"T_1c9d6_row4_col2\" class=\"data row4 col2\" >['package_summary', 'change_suggester', '__init__', 'localizer', '__init__']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x349355d00>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a copy of the DataFrame for display purposes\n",
    "display_df = evaluation_results.copy()\n",
    "\n",
    "# Transform the 'Results' columns to display only the file name\n",
    "display_df['Results (Code File Embeddings)'] = display_df['Results (Code File Embeddings)'].apply(lambda lst: [item[1] for item in lst])\n",
    "display_df['Results (Code Semantics Embeddings)'] = display_df['Results (Code Semantics Embeddings)'].apply(lambda lst: [item[1] for item in lst])\n",
    "\n",
    "# Set the index to start from 1\n",
    "display_df.index = display_df.index + 1\n",
    "\n",
    "# Apply left alignment to all columns, including headers\n",
    "df_style = display_df.style \\\n",
    "    .set_table_attributes(\"style='width:100%'\") \\\n",
    "    .set_properties(**{'text-align': 'left'}) \\\n",
    "    .set_table_styles([{\n",
    "        'selector': 'th',\n",
    "        'props': [('text-align', 'left')]\n",
    "    }])\n",
    "\n",
    "df_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
