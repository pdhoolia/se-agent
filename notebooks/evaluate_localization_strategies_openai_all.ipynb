{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate localization strategies\n",
    "\n",
    "This notebook does a comparative evaluation of different localization strategies.\n",
    "- Defines a base interface for localization\n",
    "- Implements a few localization strategies\n",
    "- Defines an evaluator that runs a test suite on those localization strategies\n",
    "- Evaluator dumps the results in a pandas dataframe\n",
    "- Uses Milvus as the vector database\n",
    "- Uses OpenAI's embeddings model\n",
    "- Uses langchain's abstractions for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import yaml\n",
    "\n",
    "from typing import Dict, List, Tuple, Iterator\n",
    "from abc import ABC, abstractmethod\n",
    "from langchain_core.documents import Document\n",
    "from langchain_milvus import Milvus\n",
    "\n",
    "from se_agent.localizer import localize_issue\n",
    "from se_agent.project import Project\n",
    "from se_agent.project_manager import ProjectManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base interface for localization strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Strategy(ABC):\n",
    "    @abstractmethod\n",
    "    def localize(self, issue: Dict[str, str], top_n: int) -> List[Tuple[str, str]]:\n",
    "        \"\"\"\n",
    "        Localizes the issue to a set of relevant packages and files.\n",
    "\n",
    "        Args:\n",
    "            issue (Dict[str, str]): A dictionary containing issue details with at least:\n",
    "                - `title` (str): The title of the issue.\n",
    "                - `description` (str): The detailed description of the issue.\n",
    "            top_n (int): The maximum number of localization results to return.\n",
    "\n",
    "        Returns:\n",
    "            List[Tuple[str, str]]: A list of tuples representing relevant localization results,\n",
    "                each containing `package` (str) and `file` (str).\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic vector search strategy\n",
    "\n",
    "This implements a simple semantic vector search strategy. It uses Milvus as the vector database and OpenAI's embeddings model. Implementation may be used as-is for multiple strategies by feeding in different types of sources. E.g.,\n",
    "- **Code file embeddings**: Providing a `source_dir` pointing to code files will directly embed code\n",
    "- **Code semantics embeddings**: Providing a `source_dir` pointing to semantic descriptions of code files will embed code semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticVectorSearchStrategy(Strategy):\n",
    "    def __init__(self, source_dir: str, root_package_name: str, embeddings, strategy_name: str):\n",
    "        self.strategy_name = strategy_name\n",
    "        self.vector_store = self.create_vector_store(source_dir, root_package_name, embeddings)\n",
    "\n",
    "    def create_vector_store(self, folder_path: str, root_package_name: str, embeddings) -> Milvus:\n",
    "        \"\"\"Creates a Milvus vector store from the files in the specified folder.\"\"\"\n",
    "        documents = self.create_documents(folder_path, root_package_name)\n",
    "        with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as tmp_file:\n",
    "            uri = tmp_file.name\n",
    "        return Milvus.from_documents(\n",
    "            documents,\n",
    "            embeddings,\n",
    "            collection_name=root_package_name,\n",
    "            connection_args={\"uri\": uri},\n",
    "        )\n",
    "    \n",
    "    def create_documents(self, folder_path: str, root_package_name: str) -> List[Document]:\n",
    "        \"\"\"Create a list of Document instances from the files in the specified folder.\"\"\"\n",
    "        documents = []\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, \"r\") as f:\n",
    "                    page_content = f.read()\n",
    "                if not page_content.strip():\n",
    "                    continue\n",
    "                filename = file.split('.')[0]\n",
    "                relative_path = os.path.relpath(root, folder_path)\n",
    "                package = (f\"{root_package_name}/{relative_path.replace(os.sep, '/')}\"\n",
    "                           if relative_path != \".\" else root_package_name)\n",
    "                document = Document(\n",
    "                    page_content=page_content,\n",
    "                    metadata={\"file\": filename, \"package\": package}\n",
    "                )\n",
    "                documents.append(document)\n",
    "        return documents\n",
    "\n",
    "    def localize(self, issue: Dict[str, str], top_n: int) -> List[Tuple[str, str]]:\n",
    "        query_string = f\"{issue['title']}: {issue['description']}\"\n",
    "        results = self.vector_store.similarity_search(query_string, k=top_n)\n",
    "        return [(res.metadata[\"package\"], res.metadata[\"file\"]) for res in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical localization strategy\n",
    "\n",
    "Instead of semantic vector search, this strategy uses the completion API to generate localization results. This requires inlining the context. Using all the files in the repository as context, far-exceed the permitted token limits of the completion API. Therefore, it uses generated semantic summaries of the code files as context. However, for large repositories, and depending on the model used, this may still exceed the token limits. Therefore, it also generates higher-level summaries at the level of packages. Let us assume that the aggregated package summaries are within the token limits. The strategy operates as follows:\n",
    "\n",
    "- **Package level**: Given an issue, it first identifies the package that are relevant to the issue query belongs to, using packages summaries in the inline context.\n",
    "- **File level**: It then identifies the files within the package that are relevant to the issue query, using file summaries for the relevant packages in the inline context.\n",
    "\n",
    "This strategy is more expensive than the semantic vector search strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalLocalizationStrategy(Strategy):\n",
    "    def __init__(self, project: Project, strategy_name: str = \"Hierarchical Completion\"):\n",
    "        self.project = project\n",
    "        self.strategy_name = strategy_name\n",
    "\n",
    "    def localize(self, issue: Dict[str, str], top_n: int) -> List[Tuple[str, str]]:\n",
    "        \"\"\"\n",
    "        Localizes an issue to specific files by first identifying relevant packages\n",
    "        and then narrowing down to specific files in those packages.\n",
    "        \"\"\"\n",
    "        # issue conversation\n",
    "        issue_conversation = {\n",
    "            \"title\": issue[\"title\"],\n",
    "            \"conversation\": [{'role': 'user', 'content': f'Issue: {issue[\"title\"]}\\n\\nDescription: {issue[\"description\"]}'}]\n",
    "        }\n",
    "\n",
    "        # Localize the issue using the hierarchical approach\n",
    "        localization_suggestions = localize_issue(self.project, issue, issue_conversation)\n",
    "\n",
    "        if localization_suggestions is None:\n",
    "            return []  # If localization fails, return an empty list\n",
    "\n",
    "        # Format the results as (package, file) tuples, sorted by confidence\n",
    "        return [(suggestion.package, os.path.splitext(suggestion.file)[0]) for suggestion in localization_suggestions[:top_n]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Issue:\n",
    "    def __init__(self, id: str, title: str, content: str, expected_results: List[str]):\n",
    "        self.id = id\n",
    "        self.title = title\n",
    "        self.content = content\n",
    "        self.expected_results = expected_results\n",
    "\n",
    "    def to_dict(self) -> Dict[str, str]:\n",
    "        \"\"\"Returns the issue data as a dictionary for easy access.\"\"\"\n",
    "        return {\"title\": self.title, \"description\": self.content}\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, yaml_path: str):\n",
    "        self.yaml_dir = os.path.dirname(yaml_path)  # Get the directory containing the YAML file\n",
    "        with open(yaml_path, 'r') as f:\n",
    "            data = yaml.safe_load(f)\n",
    "        self.test_cases = data[\"test_cases\"]\n",
    "\n",
    "    def __iter__(self) -> Iterator[Issue]:\n",
    "        \"\"\"Allows iteration over Issue instances created from test cases.\"\"\"\n",
    "        for case in self.test_cases:\n",
    "            # Construct the full path to the markdown file\n",
    "            full_path = os.path.join(self.yaml_dir, case[\"filepath\"])\n",
    "            # Load the content from the markdown file\n",
    "            with open(full_path, 'r') as f:\n",
    "                content = f.read()\n",
    "            # Create an Issue instance for each test case\n",
    "            yield Issue(\n",
    "                id=case[\"id\"],\n",
    "                title=case[\"title\"],\n",
    "                content=content,\n",
    "                expected_results=case[\"expected_results\"]\n",
    "            )\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Returns the number of test cases in the dataset.\"\"\"\n",
    "        return len(self.test_cases)\n",
    "\n",
    "dataset = Dataset(\"test/dataset.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalizationEvaluator:\n",
    "    def __init__(self, dataset: Dataset, strategies_to_evaluate: List[Strategy]):\n",
    "        self.dataset = dataset\n",
    "        self.strategies = strategies_to_evaluate\n",
    "\n",
    "    def calculate_score(self, expected_results: List[str], actual_results: List[str]) -> float:\n",
    "        \"\"\"Calculates the score with distance-based penalties for expected results outside the top-k.\"\"\"\n",
    "        score = 1.0  # Start with a perfect score of 1\n",
    "\n",
    "        for expected in expected_results:\n",
    "            if expected in actual_results:\n",
    "                index = actual_results.index(expected)\n",
    "                # Check if expected item is within the top-k\n",
    "                if index >= len(expected_results):\n",
    "                    # Distance-based partial penalty if it's outside top-k but present in results\n",
    "                    distance_factor = index - len(expected_results) + 1\n",
    "                    penalty = (1 / len(expected_results)) * distance_factor * 0.2\n",
    "                    score -= penalty\n",
    "            else:\n",
    "                # Full penalty if expected item is missing altogether\n",
    "                score -= 1 / len(expected_results)\n",
    "\n",
    "        return max(score, 0)  # Ensure score doesn't go below 0\n",
    "\n",
    "    def evaluate(self) -> pd.DataFrame:\n",
    "        \"\"\"Evaluates each strategy on all test issues and returns a DataFrame with results and scores.\"\"\"\n",
    "        df = pd.DataFrame(columns=[\"Issue Title\", \"Expected Results\"] + [f\"Results ({strategy.strategy_name})\" for strategy in self.strategies])\n",
    "\n",
    "        # Dictionary to store total scores per strategy\n",
    "        total_scores = {strategy.strategy_name: 0 for strategy in self.strategies}\n",
    "\n",
    "        # Iterate over each Issue in the dataset\n",
    "        for issue in self.dataset:\n",
    "            issue_data = {\"title\": issue.title, \"description\": issue.content}  # Prepare data for localization\n",
    "            row_data = {\n",
    "                \"Issue Title\": issue.title,\n",
    "                \"Expected Results\": issue.expected_results\n",
    "            }\n",
    "\n",
    "            # Calculate and store results and formatted score+results for each strategy\n",
    "            for strategy in self.strategies:\n",
    "                actual_results = [res[1] for res in strategy.localize(issue_data, top_n=5)]\n",
    "                score = self.calculate_score(issue.expected_results, actual_results)\n",
    "                total_scores[strategy.strategy_name] += score  # Accumulate score for total\n",
    "\n",
    "                # Format results with score as requested\n",
    "                formatted_result = f\"{score:.2f} {actual_results}\"\n",
    "                row_data[f\"Results ({strategy.strategy_name})\"] = formatted_result\n",
    "\n",
    "            # Append row data to DataFrame\n",
    "            df = pd.concat([df, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "        # Append total scores row to DataFrame\n",
    "        total_row = {\"Issue Title\": \"Score\", \"Expected Results\": \"\"}\n",
    "        for strategy in self.strategies:\n",
    "            total_row[f\"Results ({strategy.strategy_name})\"] = f\"{(total_scores[strategy.strategy_name]/len(self.dataset))*100:.2f}%\"\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame([total_row])], ignore_index=True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LLM_PROVIDER_NAME\"] = \"openai\"\n",
    "\n",
    "projects_store = \"/Users/pdhoolia/projects-store\"\n",
    "repo_full_name = \"pdhoolia/se-agent\"\n",
    "src_dir = \"se_agent\"\n",
    "\n",
    "code_dir = os.path.join(projects_store, repo_full_name, \"repo\", src_dir)\n",
    "code_semantics_dir = os.path.join(projects_store, repo_full_name, \"metadata\", \"package_details\")\n",
    "\n",
    "project_manager = ProjectManager(projects_store)\n",
    "project_info = project_manager.get_project(repo_full_name)\n",
    "project = Project(os.getenv(\"GITHUB_TOKEN\"), projects_store, project_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create combinded semantic summary + Code files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary directory for the combined documents\n",
    "combined_docs_dir = tempfile.mkdtemp()\n",
    "\n",
    "# Iterate over the semantic summaries and combine with corresponding code files\n",
    "for root, _, files in os.walk(code_semantics_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".md\"):\n",
    "            filename_without_extn = file.split('.')[0]\n",
    "            summary_file_path = os.path.join(root, file)\n",
    "            # Get corresponding code file path\n",
    "            relative_path = os.path.relpath(root, code_semantics_dir)\n",
    "            code_file_path = os.path.join(code_dir, relative_path, f\"{filename_without_extn}.py\")\n",
    "            \n",
    "            # Only proceed if the code file exists\n",
    "            if os.path.exists(code_file_path):\n",
    "                # Read content from both summary and code files\n",
    "                with open(summary_file_path, \"r\") as summary_file:\n",
    "                    semantic_summary_content = summary_file.read()\n",
    "                with open(code_file_path, \"r\") as code_file:\n",
    "                    code_content = code_file.read()\n",
    "                \n",
    "                # Combine the contents\n",
    "                combined_content = f\"# Semantic summary\\n\\n{semantic_summary_content}\\n\\n# Code\\n\\n```python\\n{code_content}\\n```\"\n",
    "                \n",
    "                # Define path for the combined document in the temporary folder\n",
    "                combined_file_dir = os.path.join(combined_docs_dir, relative_path)\n",
    "                os.makedirs(combined_file_dir, exist_ok=True)\n",
    "                combined_file_path = os.path.join(combined_file_dir, f\"{filename_without_extn}.md\")\n",
    "                \n",
    "                # Save the combined content\n",
    "                with open(combined_file_path, \"w\") as combined_file:\n",
    "                    combined_file.write(combined_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strategies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_file_embeddings = SemanticVectorSearchStrategy(code_dir, src_dir, embeddings, strategy_name=\"Code File Embeddings\")\n",
    "code_semantics_embeddings = SemanticVectorSearchStrategy(code_semantics_dir, src_dir, embeddings, strategy_name=\"Code Semantics Embeddings\")\n",
    "combined_embeddings = SemanticVectorSearchStrategy(combined_docs_dir, src_dir, embeddings, strategy_name=\"Combined Embeddings\")\n",
    "hierarchical_strategy = HierarchicalLocalizationStrategy(project, strategy_name=\"Hierarchical Localization\")\n",
    "\n",
    "strategies_to_evaluate = [code_file_embeddings, code_semantics_embeddings, combined_embeddings, hierarchical_strategy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 13:56:59,317 - se-agent - DEBUG - Relevant Packages: ['se_agent']\n",
      "2024-11-17 13:57:01,136 - se-agent - DEBUG - File Localization Suggestions: [FileLocalizationSuggestion(package='se_agent', file='project_info.py', confidence=0.9, reason='This file defines the ProjectInfo class, which stores metadata like the GitHub token for projects.'), FileLocalizationSuggestion(package='se_agent', file='project_manager.py', confidence=0.85, reason='Manages project data including loading and saving project information, relevant for handling GitHub tokens.'), FileLocalizationSuggestion(package='se_agent', file='onboard_agent.py', confidence=0.8, reason='Facilitates project onboarding and uses environment variables and ProjectManager, relevant for GitHub token management.')]\n",
      "2024-11-17 13:57:04,540 - se-agent - DEBUG - Relevant Packages: ['llm']\n",
      "2024-11-17 13:57:12,753 - se-agent - DEBUG - File Localization Suggestions: [FileLocalizationSuggestion(package='llm', file='api.py', confidence=0.8, reason='Handles LLM invocation and response formatting, likely place for retry logic.'), FileLocalizationSuggestion(package='llm', file='retry_with_backoff.py', confidence=0.9, reason='Defines retry mechanism with exponential backoff, applicable for handling RateLimitError.')]\n",
      "2024-11-17 13:57:16,748 - se-agent - DEBUG - Relevant Packages: ['se_agent', 'llm']\n",
      "2024-11-17 13:57:25,606 - se-agent - DEBUG - File Localization Suggestions: [FileLocalizationSuggestion(package='se_agent', file='listener_core.py', confidence=0.95, reason='Handles GitHub webhook events and would need updates to process issue comment events.'), FileLocalizationSuggestion(package='se_agent', file='issue_analyzer.py', confidence=0.9, reason='Analyzes GitHub issues and will need modifications to handle comments in the analysis.'), FileLocalizationSuggestion(package='se_agent', file='localizer.py', confidence=0.85, reason='Responsible for localizing issues to specific files and will need updates to handle conversation threads.'), FileLocalizationSuggestion(package='se_agent', file='change_suggester.py', confidence=0.8, reason='Generates change suggestions, requiring updates to process structured prompts with conversation threads.'), FileLocalizationSuggestion(package='llm', file='api.py', confidence=0.75, reason='Handles LLM interactions and will need refactoring to accept structured prompts with messages.')]\n",
      "2024-11-17 13:57:48,168 - se-agent - DEBUG - Relevant Packages: ['repository_analyzer', 'se_agent']\n",
      "2024-11-17 13:57:50,105 - se-agent - DEBUG - File Localization Suggestions: [FileLocalizationSuggestion(package='repository_analyzer', file='file_analyzer.py', confidence=0.9, reason='Handles generation of package details and file level semantic summaries, which need updates on code changes.'), FileLocalizationSuggestion(package='repository_analyzer', file='package_summary.py', confidence=0.85, reason='Responsible for generating package summaries, which need refreshing on code updates.'), FileLocalizationSuggestion(package='se_agent', file='listener_core.py', confidence=0.9, reason='Processes webhook events and needs enhancement to handle code push events.'), FileLocalizationSuggestion(package='se_agent', file='project.py', confidence=0.8, reason='Interfaces with GitHub API and manages metadata, crucial for handling new code pushes.')]\n",
      "2024-11-17 13:57:53,786 - se-agent - DEBUG - Relevant Packages: ['se_agent', 'lambda']\n",
      "2024-11-17 13:58:08,809 - se-agent - DEBUG - File Localization Suggestions: [FileLocalizationSuggestion(package='se_agent', file='flask_server.py', confidence=0.9, reason=\"Defines routes including onboarding, needs new route for '/onboard' with POST/PUT for project onboarding.\"), FileLocalizationSuggestion(package='lambda', file='lambda_function.py', confidence=0.85, reason=\"Handles web requests for onboarding projects, should support the '/onboard' path with POST/PUT.\"), FileLocalizationSuggestion(package='se_agent', file='project_info.py', confidence=0.75, reason=\"Defines the 'ProjectInfo' data structure needed for the '/onboard' route for project onboarding.\"), FileLocalizationSuggestion(package='se_agent', file='project_manager.py', confidence=0.7, reason='Manages project data, relevant for adding and updating projects during onboarding via API.'), FileLocalizationSuggestion(package='se_agent', file='onboard_agent.py', confidence=0.65, reason='Handles project onboarding processes, relevant for triggering onboarding after adding a project.')]\n",
      "2024-11-17 13:58:12,956 - se-agent - DEBUG - Relevant Packages: ['lambda', 'se_agent']\n",
      "2024-11-17 13:58:14,489 - se-agent - DEBUG - File Localization Suggestions: [FileLocalizationSuggestion(package='lambda', file='lambda_function.py', confidence=0.95, reason='The issue directly involves relocating this file within the se_agent package structure.'), FileLocalizationSuggestion(package='se_agent', file='__init__.py', confidence=0.85, reason='This file may need adjustments to incorporate the new lambda sub-package.')]\n",
      "2024-11-17 13:58:56,197 - se-agent - DEBUG - Relevant Packages: ['repository_analyzer', 'se_agent']\n",
      "2024-11-17 13:58:59,539 - se-agent - DEBUG - File Localization Suggestions: [FileLocalizationSuggestion(package='repository_analyzer', file='file_analyzer.py', confidence=0.9, reason='Handles semantic description generation for files, relevant to structured output.'), FileLocalizationSuggestion(package='repository_analyzer', file='package_summary.py', confidence=0.85, reason='Generates semantic summaries for packages, relevant to the new structured output.'), FileLocalizationSuggestion(package='se_agent', file='localizer.py', confidence=0.8, reason='Uses structured output parsing, relevant to implementing similar approach for summaries.'), FileLocalizationSuggestion(package='se_agent', file='listener_core.py', confidence=0.7, reason='Manages integration and issue processing, indirectly related to updating codebase understanding.'), FileLocalizationSuggestion(package='se_agent', file='project.py', confidence=0.75, reason='Contains `update_codebase_understanding` function, directly impacted by the change.')]\n",
      "2024-11-17 13:59:02,870 - se-agent - DEBUG - Relevant Packages: ['repository_analyzer', 'util']\n",
      "2024-11-17 13:59:04,345 - se-agent - DEBUG - File Localization Suggestions: [FileLocalizationSuggestion(package='repository_analyzer', file='package_summary.py', confidence=0.95, reason='This file handles package summary generation using LLM, so it needs modification to change the strategy.'), FileLocalizationSuggestion(package='repository_analyzer', file='file_analyzer.py', confidence=0.85, reason='This file involves generating semantic descriptions of Python files, which may be needed for extracting code structure names.')]\n",
      "2024-11-17 13:59:08,748 - se-agent - DEBUG - Relevant Packages: ['se_agent', 'llm']\n",
      "2024-11-17 13:59:10,604 - se-agent - DEBUG - File Localization Suggestions: [FileLocalizationSuggestion(package='se_agent', file='localizer.py', confidence=0.95, reason='The file implements the existing localization strategy and will need modification to incorporate retrieval-based methods.'), FileLocalizationSuggestion(package='llm', file='api.py', confidence=0.9, reason='Enhancements to LLM interfacing for embedding models and new task configurations are required here.'), FileLocalizationSuggestion(package='se_agent', file='onboard_agent.py', confidence=0.85, reason='Onboarding process modifications to integrate vector index creation will be implemented here.'), FileLocalizationSuggestion(package='se_agent', file='project.py', confidence=0.8, reason='The Project class manages onboarding and will need updates to handle vector index creation.')]\n",
      "2024-11-17 13:59:14,326 - se-agent - DEBUG - Relevant Packages: ['se_agent']\n",
      "2024-11-17 13:59:15,469 - se-agent - DEBUG - File Localization Suggestions: [FileLocalizationSuggestion(package='se_agent', file='project.py', confidence=0.95, reason='Contains functions for loading, saving, and deleting checkpoints during semantic analysis.')]\n",
      "2024-11-17 13:59:19,817 - se-agent - DEBUG - Relevant Packages: ['se_agent']\n",
      "2024-11-17 13:59:21,216 - se-agent - DEBUG - File Localization Suggestions: [FileLocalizationSuggestion(package='se_agent', file='project.py', confidence=0.85, reason='Manages fetching of code files for semantic analysis and change suggestions.'), FileLocalizationSuggestion(package='se_agent', file='localizer.py', confidence=0.75, reason='Handles localization of issues to specific files which may involve package name resolutions.')]\n",
      "2024-11-17 13:59:24,259 - se-agent - DEBUG - Relevant Packages: ['se_agent']\n",
      "2024-11-17 13:59:25,979 - se-agent - DEBUG - File Localization Suggestions: [FileLocalizationSuggestion(package='se_agent', file='localizer.py', confidence=0.95, reason='Handles issue localization and uses top_n configurations to manage data size for LLM context.'), FileLocalizationSuggestion(package='se_agent', file='change_suggester.py', confidence=0.9, reason='Utilizes top_n_files configuration to suggest changes, relevant for project-level overrides.'), FileLocalizationSuggestion(package='se_agent', file='project_info.py', confidence=0.85, reason='Defines project-level metadata, suitable for adding configurations for top-n packages/files.')]\n",
      "2024-11-17 13:59:42,131 - se-agent - DEBUG - Relevant Packages: ['repository_analyzer']\n",
      "2024-11-17 13:59:43,258 - se-agent - DEBUG - File Localization Suggestions: [FileLocalizationSuggestion(package='repository_analyzer', file='file_analyzer.py', confidence=0.95, reason='Handles checking for empty files before generating semantic descriptions.')]\n",
      "2024-11-17 13:59:47,215 - se-agent - DEBUG - Relevant Packages: ['se_agent']\n",
      "2024-11-17 14:00:03,151 - se-agent - DEBUG - File Localization Suggestions: [FileLocalizationSuggestion(package='se_agent', file='project.py', confidence=0.95, reason=\"The error occurs in the 'save_checkpoint' function of 'project.py', which deals with saving checkpoints.\"), FileLocalizationSuggestion(package='se_agent', file='project_manager.py', confidence=0.7, reason='This file manages project data, which may include checkpoint handling.')]\n",
      "2024-11-17 14:00:25,300 - se-agent - DEBUG - Relevant Packages: ['se_agent']\n",
      "2024-11-17 14:00:27,201 - se-agent - DEBUG - File Localization Suggestions: [FileLocalizationSuggestion(package='se_agent', file='listener_core.py', confidence=0.9, reason='Handles project onboarding and triggers the onboarding process where the error occurs.'), FileLocalizationSuggestion(package='se_agent', file='project.py', confidence=0.95, reason='Manages the onboarding process and contains the `clone_repository` function where the error is raised.'), FileLocalizationSuggestion(package='se_agent', file='project_manager.py', confidence=0.7, reason='Handles project storage, which may relate to the file path issue during onboarding.')]\n",
      "2024-11-17 14:00:54,321 - se-agent - DEBUG - Relevant Packages: ['se_agent']\n",
      "2024-11-17 14:01:04,507 - se-agent - DEBUG - File Localization Suggestions: [FileLocalizationSuggestion(package='se_agent', file='listener_core.py', confidence=0.95, reason='Processes GitHub webhook events and handles issue comments, which is relevant to ignoring comments on closed issues.'), FileLocalizationSuggestion(package='se_agent', file='issue_analyzer.py', confidence=0.75, reason='Analyzes issues and comments; relevant to determining issue state and handling comments accordingly.')]\n",
      "2024-11-17 14:01:07,635 - se-agent - DEBUG - Relevant Packages: ['lambda', 'se_agent']\n",
      "2024-11-17 14:01:20,580 - se-agent - DEBUG - File Localization Suggestions: [FileLocalizationSuggestion(package='lambda', file='lambda_function.py', confidence=0.9, reason='The file handles `/onboard` events and should be refactored for asynchronous processing.'), FileLocalizationSuggestion(package='se_agent', file='flask_server.py', confidence=0.85, reason='Contains the Flask server setup, relevant for refactoring `/onboard` to asynchronous processing.'), FileLocalizationSuggestion(package='se_agent', file='listener_core.py', confidence=0.8, reason='Processes GitHub webhook events and may need refactoring for handling long running operations.'), FileLocalizationSuggestion(package='se_agent', file='onboard_agent.py', confidence=0.75, reason='Manages project onboarding which involves long-running operations like cloning and processing repositories.')]\n",
      "2024-11-17 14:01:23,636 - se-agent - DEBUG - Relevant Packages: ['se_agent']\n",
      "2024-11-17 14:01:25,966 - se-agent - DEBUG - File Localization Suggestions: [FileLocalizationSuggestion(package='se_agent', file='listener_core.py', confidence=0.95, reason=\"This file processes GitHub webhook events and handles issue comments and labeling, relevant for detecting and acting on 'off-limit' labels.\"), FileLocalizationSuggestion(package='se_agent', file='issue_analyzer.py', confidence=0.85, reason=\"This file analyzes issues and comments, crucial for implementing logic to ignore comments on 'off-limit' labeled issues.\")]\n",
      "2024-11-17 14:01:49,484 - se-agent - DEBUG - Relevant Packages: ['se_agent', 'llm']\n",
      "2024-11-17 14:01:52,591 - se-agent - DEBUG - File Localization Suggestions: [FileLocalizationSuggestion(package='se_agent', file='listener_core.py', confidence=0.95, reason='Contains the core logic for processing issues and handling webhook events, ideal for adding decision making logic.'), FileLocalizationSuggestion(package='llm', file='api.py', confidence=0.85, reason=\"Relevant for implementing the new LLM task 'response_decision' for decision making.\"), FileLocalizationSuggestion(package='se_agent', file='issue_analyzer.py', confidence=0.75, reason='Involved in analyzing issues, which is the first step in the decision-making process.'), FileLocalizationSuggestion(package='se_agent', file='change_suggester.py', confidence=0.65, reason='Related to generating suggestions, which may be bypassed based on the new decision logic.'), FileLocalizationSuggestion(package='se_agent', file='flask_server.py', confidence=0.6, reason='Handles webhook events and could be involved in initiating the decision process.')]\n",
      "2024-11-17 14:02:05,286 - se-agent - DEBUG - Relevant Packages: ['se_agent', 'llm']\n",
      "2024-11-17 14:02:07,336 - se-agent - DEBUG - File Localization Suggestions: [FileLocalizationSuggestion(package='se_agent', file='issue_analyzer.py', confidence=0.85, reason='The file is responsible for analyzing issue comments, which aligns with identifying domain understanding corrections.'), FileLocalizationSuggestion(package='se_agent', file='listener_core.py', confidence=0.8, reason='Processes issue comments and suggestions; relevant for integrating domain memory understanding.'), FileLocalizationSuggestion(package='llm', file='api.py', confidence=0.75, reason='Involves invoking language models, which is crucial for generating and storing condensed memories.'), FileLocalizationSuggestion(package='llm', file='model_configuration_manager.py', confidence=0.7, reason='Manages LLM task configurations, relevant for adding new tasks for memory generation.')]\n",
      "2024-11-17 14:02:24,350 - se-agent - DEBUG - Relevant Packages: ['se_agent']\n",
      "2024-11-17 14:02:26,832 - se-agent - DEBUG - File Localization Suggestions: [FileLocalizationSuggestion(package='se_agent', file='flask_server.py', confidence=0.85, reason='This file sets up the Flask web server and handles API endpoints, making it relevant for adding new endpoints.'), FileLocalizationSuggestion(package='se_agent', file='listener_core.py', confidence=0.75, reason='Handles GitHub integration and processes webhook events, potentially interacting with memory management.'), FileLocalizationSuggestion(package='se_agent', file='project_manager.py', confidence=0.65, reason='Manages project data, which may involve storing and retrieving memories related to projects.')]\n",
      "2024-11-17 14:02:30,168 - se-agent - DEBUG - Relevant Packages: ['se_agent']\n",
      "2024-11-17 14:02:31,812 - se-agent - DEBUG - File Localization Suggestions: [FileLocalizationSuggestion(package='se_agent', file='project.py', confidence=0.95, reason='The Project class manages onboarding, analysis, and documentation generation, making it central for caching package details.'), FileLocalizationSuggestion(package='se_agent', file='project_manager.py', confidence=0.85, reason='The ProjectManager class handles project data, which may include managing caches for package details.'), FileLocalizationSuggestion(package='se_agent', file='localizer.py', confidence=0.8, reason='Localizer interacts with package details during issue processing, relevant for cache integration.')]\n",
      "2024-11-17 14:02:34,842 - se-agent - DEBUG - Relevant Packages: ['se_agent']\n",
      "2024-11-17 14:02:42,932 - se-agent - DEBUG - File Localization Suggestions: [FileLocalizationSuggestion(package='se_agent', file='project.py', confidence=0.9, reason='Manages onboarding and analysis of GitHub repositories, including generating package details.'), FileLocalizationSuggestion(package='se_agent', file='project_manager.py', confidence=0.75, reason='Manages project data and may need updates for cache integration.'), FileLocalizationSuggestion(package='se_agent', file='project_info.py', confidence=0.7, reason='Stores project metadata, which may involve storing cache settings.')]\n",
      "2024-11-17 14:02:48,061 - se-agent - DEBUG - Relevant Packages: ['repository_analyzer', 'se_agent']\n",
      "2024-11-17 14:02:49,832 - se-agent - DEBUG - File Localization Suggestions: [FileLocalizationSuggestion(package='repository_analyzer', file='file_analyzer.py', confidence=0.85, reason='This file handles the generation of semantic descriptions of code files. It would need modification to extend support to non-code files.'), FileLocalizationSuggestion(package='repository_analyzer', file='package_summary.py', confidence=0.8, reason='This file generates semantic summaries for packages and would need changes to include non-code files.'), FileLocalizationSuggestion(package='se_agent', file='change_suggester.py', confidence=0.75, reason='The change suggester relies on semantic descriptions and would need updates to consider non-code files.')]\n",
      "2024-11-17 14:02:52,699 - se-agent - DEBUG - Relevant Packages: ['se_agent', 'repository_analyzer', 'util']\n",
      "2024-11-17 14:03:01,075 - se-agent - DEBUG - File Localization Suggestions: [FileLocalizationSuggestion(package='se_agent', file='localizer.py', confidence=0.85, reason='Handles issue localization by identifying relevant files, suggesting expansion to non-code files.'), FileLocalizationSuggestion(package='repository_analyzer', file='file_analyzer.py', confidence=0.8, reason='Generates semantic descriptions for code files, can be extended to other file types.')]\n"
     ]
    }
   ],
   "source": [
    "evaluator = LocalizationEvaluator(\n",
    "    dataset=dataset,\n",
    "    strategies_to_evaluate=strategies_to_evaluate\n",
    ")\n",
    "\n",
    "evaluation_results = evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_819f4 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_819f4_row0_col0, #T_819f4_row0_col1, #T_819f4_row0_col2, #T_819f4_row0_col3, #T_819f4_row0_col4, #T_819f4_row0_col5, #T_819f4_row1_col0, #T_819f4_row1_col1, #T_819f4_row1_col2, #T_819f4_row1_col3, #T_819f4_row1_col4, #T_819f4_row1_col5, #T_819f4_row2_col0, #T_819f4_row2_col1, #T_819f4_row2_col2, #T_819f4_row2_col3, #T_819f4_row2_col4, #T_819f4_row2_col5, #T_819f4_row3_col0, #T_819f4_row3_col1, #T_819f4_row3_col2, #T_819f4_row3_col3, #T_819f4_row3_col4, #T_819f4_row3_col5, #T_819f4_row4_col0, #T_819f4_row4_col1, #T_819f4_row4_col2, #T_819f4_row4_col3, #T_819f4_row4_col4, #T_819f4_row4_col5, #T_819f4_row5_col0, #T_819f4_row5_col1, #T_819f4_row5_col2, #T_819f4_row5_col3, #T_819f4_row5_col4, #T_819f4_row5_col5, #T_819f4_row6_col0, #T_819f4_row6_col1, #T_819f4_row6_col2, #T_819f4_row6_col3, #T_819f4_row6_col4, #T_819f4_row6_col5, #T_819f4_row7_col0, #T_819f4_row7_col1, #T_819f4_row7_col2, #T_819f4_row7_col3, #T_819f4_row7_col4, #T_819f4_row7_col5, #T_819f4_row8_col0, #T_819f4_row8_col1, #T_819f4_row8_col2, #T_819f4_row8_col3, #T_819f4_row8_col4, #T_819f4_row8_col5, #T_819f4_row9_col0, #T_819f4_row9_col1, #T_819f4_row9_col2, #T_819f4_row9_col3, #T_819f4_row9_col4, #T_819f4_row9_col5, #T_819f4_row10_col0, #T_819f4_row10_col1, #T_819f4_row10_col2, #T_819f4_row10_col3, #T_819f4_row10_col4, #T_819f4_row10_col5, #T_819f4_row11_col0, #T_819f4_row11_col1, #T_819f4_row11_col2, #T_819f4_row11_col3, #T_819f4_row11_col4, #T_819f4_row11_col5, #T_819f4_row12_col0, #T_819f4_row12_col1, #T_819f4_row12_col2, #T_819f4_row12_col3, #T_819f4_row12_col4, #T_819f4_row12_col5, #T_819f4_row13_col0, #T_819f4_row13_col1, #T_819f4_row13_col2, #T_819f4_row13_col3, #T_819f4_row13_col4, #T_819f4_row13_col5, #T_819f4_row14_col0, #T_819f4_row14_col1, #T_819f4_row14_col2, #T_819f4_row14_col3, #T_819f4_row14_col4, #T_819f4_row14_col5, #T_819f4_row15_col0, #T_819f4_row15_col1, #T_819f4_row15_col2, #T_819f4_row15_col3, #T_819f4_row15_col4, #T_819f4_row15_col5, #T_819f4_row16_col0, #T_819f4_row16_col1, #T_819f4_row16_col2, #T_819f4_row16_col3, #T_819f4_row16_col4, #T_819f4_row16_col5, #T_819f4_row17_col0, #T_819f4_row17_col1, #T_819f4_row17_col2, #T_819f4_row17_col3, #T_819f4_row17_col4, #T_819f4_row17_col5, #T_819f4_row18_col0, #T_819f4_row18_col1, #T_819f4_row18_col2, #T_819f4_row18_col3, #T_819f4_row18_col4, #T_819f4_row18_col5, #T_819f4_row19_col0, #T_819f4_row19_col1, #T_819f4_row19_col2, #T_819f4_row19_col3, #T_819f4_row19_col4, #T_819f4_row19_col5, #T_819f4_row20_col0, #T_819f4_row20_col1, #T_819f4_row20_col2, #T_819f4_row20_col3, #T_819f4_row20_col4, #T_819f4_row20_col5, #T_819f4_row21_col0, #T_819f4_row21_col1, #T_819f4_row21_col2, #T_819f4_row21_col3, #T_819f4_row21_col4, #T_819f4_row21_col5, #T_819f4_row22_col0, #T_819f4_row22_col1, #T_819f4_row22_col2, #T_819f4_row22_col3, #T_819f4_row22_col4, #T_819f4_row22_col5, #T_819f4_row23_col0, #T_819f4_row23_col1, #T_819f4_row23_col2, #T_819f4_row23_col3, #T_819f4_row23_col4, #T_819f4_row23_col5, #T_819f4_row24_col0, #T_819f4_row24_col1, #T_819f4_row24_col2, #T_819f4_row24_col3, #T_819f4_row24_col4, #T_819f4_row24_col5, #T_819f4_row25_col0, #T_819f4_row25_col1, #T_819f4_row25_col2, #T_819f4_row25_col3, #T_819f4_row25_col4, #T_819f4_row25_col5 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_819f4\" style='width:100%'>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_819f4_level0_col0\" class=\"col_heading level0 col0\" >Issue Title</th>\n",
       "      <th id=\"T_819f4_level0_col1\" class=\"col_heading level0 col1\" >Expected Results</th>\n",
       "      <th id=\"T_819f4_level0_col2\" class=\"col_heading level0 col2\" >Results (Code File Embeddings)</th>\n",
       "      <th id=\"T_819f4_level0_col3\" class=\"col_heading level0 col3\" >Results (Code Semantics Embeddings)</th>\n",
       "      <th id=\"T_819f4_level0_col4\" class=\"col_heading level0 col4\" >Results (Combined Embeddings)</th>\n",
       "      <th id=\"T_819f4_level0_col5\" class=\"col_heading level0 col5\" >Results (Hierarchical Localization)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_819f4_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_819f4_row0_col0\" class=\"data row0 col0\" >Project level override for github token</td>\n",
       "      <td id=\"T_819f4_row0_col1\" class=\"data row0 col1\" >['project', 'project_info', 'onboard_agent']</td>\n",
       "      <td id=\"T_819f4_row0_col2\" class=\"data row0 col2\" >0.87 ['onboard_agent', 'project_info', 'listener_core', 'lambda_function', 'project']</td>\n",
       "      <td id=\"T_819f4_row0_col3\" class=\"data row0 col3\" >0.93 ['listener_core', 'onboard_agent', 'project_info', 'project', 'lambda_function']</td>\n",
       "      <td id=\"T_819f4_row0_col4\" class=\"data row0 col4\" >0.93 ['listener_core', 'onboard_agent', 'project_info', 'project', 'flask_server']</td>\n",
       "      <td id=\"T_819f4_row0_col5\" class=\"data row0 col5\" >0.67 ['project_info', 'project_manager', 'onboard_agent']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_819f4_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_819f4_row1_col0\" class=\"data row1 col0\" >Retry LLM call on Rate Limit Error</td>\n",
       "      <td id=\"T_819f4_row1_col1\" class=\"data row1 col1\" >['retry_with_backoff', 'api']</td>\n",
       "      <td id=\"T_819f4_row1_col2\" class=\"data row1 col2\" >0.90 ['api', 'localizer', 'retry_with_backoff', 'change_suggester', 'project']</td>\n",
       "      <td id=\"T_819f4_row1_col3\" class=\"data row1 col3\" >1.00 ['api', 'retry_with_backoff', 'lambda_function', 'change_suggester', 'listener_core']</td>\n",
       "      <td id=\"T_819f4_row1_col4\" class=\"data row1 col4\" >1.00 ['api', 'retry_with_backoff', 'change_suggester', 'localizer', 'lambda_function']</td>\n",
       "      <td id=\"T_819f4_row1_col5\" class=\"data row1 col5\" >1.00 ['api', 'retry_with_backoff']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_819f4_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_819f4_row2_col0\" class=\"data row2 col0\" >Handle issue comments as well</td>\n",
       "      <td id=\"T_819f4_row2_col1\" class=\"data row2 col1\" >['listener_core', 'issue_analyzer', 'localizer', 'change_suggester', 'project']</td>\n",
       "      <td id=\"T_819f4_row2_col2\" class=\"data row2 col2\" >1.00 ['listener_core', 'project', 'issue_analyzer', 'localizer', 'change_suggester']</td>\n",
       "      <td id=\"T_819f4_row2_col3\" class=\"data row2 col3\" >0.80 ['listener_core', 'issue_analyzer', 'change_suggester', 'localizer', 'onboard_agent']</td>\n",
       "      <td id=\"T_819f4_row2_col4\" class=\"data row2 col4\" >1.00 ['listener_core', 'issue_analyzer', 'project', 'change_suggester', 'localizer']</td>\n",
       "      <td id=\"T_819f4_row2_col5\" class=\"data row2 col5\" >0.80 ['listener_core', 'issue_analyzer', 'localizer', 'change_suggester', 'api']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_819f4_level0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "      <td id=\"T_819f4_row3_col0\" class=\"data row3 col0\" >Update semantic understanding on code push to the main branch</td>\n",
       "      <td id=\"T_819f4_row3_col1\" class=\"data row3 col1\" >['listener_core', 'project', 'file_analyzer', 'package_summary']</td>\n",
       "      <td id=\"T_819f4_row3_col2\" class=\"data row3 col2\" >0.50 ['project', 'listener_core', 'localizer', 'change_suggester', 'issue_analyzer']</td>\n",
       "      <td id=\"T_819f4_row3_col3\" class=\"data row3 col3\" >0.25 ['listener_core', 'change_suggester', 'localizer', 'onboard_agent', 'issue_analyzer']</td>\n",
       "      <td id=\"T_819f4_row3_col4\" class=\"data row3 col4\" >0.50 ['listener_core', 'localizer', 'change_suggester', 'project', 'issue_analyzer']</td>\n",
       "      <td id=\"T_819f4_row3_col5\" class=\"data row3 col5\" >1.00 ['file_analyzer', 'package_summary', 'listener_core', 'project']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_819f4_level0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "      <td id=\"T_819f4_row4_col0\" class=\"data row4 col0\" >API based onboarding for a new project</td>\n",
       "      <td id=\"T_819f4_row4_col1\" class=\"data row4 col1\" >['listener_core', 'flask_server', 'lambda_function', 'project_manager', 'project']</td>\n",
       "      <td id=\"T_819f4_row4_col2\" class=\"data row4 col2\" >0.80 ['onboard_agent', 'flask_server', 'listener_core', 'lambda_function', 'project_manager']</td>\n",
       "      <td id=\"T_819f4_row4_col3\" class=\"data row4 col3\" >0.80 ['onboard_agent', 'flask_server', 'listener_core', 'lambda_function', 'project']</td>\n",
       "      <td id=\"T_819f4_row4_col4\" class=\"data row4 col4\" >0.80 ['onboard_agent', 'flask_server', 'listener_core', 'lambda_function', 'project']</td>\n",
       "      <td id=\"T_819f4_row4_col5\" class=\"data row4 col5\" >0.60 ['flask_server', 'lambda_function', 'project_info', 'project_manager', 'onboard_agent']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_819f4_level0_row5\" class=\"row_heading level0 row5\" >6</th>\n",
       "      <td id=\"T_819f4_row5_col0\" class=\"data row5 col0\" >Move lambda function within the se_agent package structure</td>\n",
       "      <td id=\"T_819f4_row5_col1\" class=\"data row5 col1\" >['lambda_function']</td>\n",
       "      <td id=\"T_819f4_row5_col2\" class=\"data row5 col2\" >1.00 ['lambda_function', 'localizer', 'onboard_agent', 'project', '__init__']</td>\n",
       "      <td id=\"T_819f4_row5_col3\" class=\"data row5 col3\" >1.00 ['lambda_function', 'onboard_agent', '__init__', 'listener_core', 'localizer']</td>\n",
       "      <td id=\"T_819f4_row5_col4\" class=\"data row5 col4\" >1.00 ['lambda_function', 'localizer', 'listener_core', 'change_suggester', 'package_summary']</td>\n",
       "      <td id=\"T_819f4_row5_col5\" class=\"data row5 col5\" >1.00 ['lambda_function', '__init__']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_819f4_level0_row6\" class=\"row_heading level0 row6\" >7</th>\n",
       "      <td id=\"T_819f4_row6_col0\" class=\"data row6 col0\" >Use structured output for semantic summary generation</td>\n",
       "      <td id=\"T_819f4_row6_col1\" class=\"data row6 col1\" >['localizer', 'file_analyzer', 'package_summary', 'project']</td>\n",
       "      <td id=\"T_819f4_row6_col2\" class=\"data row6 col2\" >0.95 ['package_summary', 'change_suggester', 'localizer', 'project', 'file_analyzer']</td>\n",
       "      <td id=\"T_819f4_row6_col3\" class=\"data row6 col3\" >0.75 ['change_suggester', 'package_summary', 'file_analyzer', 'localizer', 'api']</td>\n",
       "      <td id=\"T_819f4_row6_col4\" class=\"data row6 col4\" >0.75 ['package_summary', 'file_analyzer', 'change_suggester', 'localizer', 'api']</td>\n",
       "      <td id=\"T_819f4_row6_col5\" class=\"data row6 col5\" >0.95 ['file_analyzer', 'package_summary', 'localizer', 'listener_core', 'project']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_819f4_level0_row7\" class=\"row_heading level0 row7\" >8</th>\n",
       "      <td id=\"T_819f4_row7_col0\" class=\"data row7 col0\" >Tool based (no LLM) code structure name generation</td>\n",
       "      <td id=\"T_819f4_row7_col1\" class=\"data row7 col1\" >['package_summary', 'project']</td>\n",
       "      <td id=\"T_819f4_row7_col2\" class=\"data row7 col2\" >0.70 ['package_summary', 'change_suggester', 'localizer', 'file_analyzer', 'project']</td>\n",
       "      <td id=\"T_819f4_row7_col3\" class=\"data row7 col3\" >0.50 ['package_summary', 'change_suggester', 'file_analyzer', 'localizer', 'api']</td>\n",
       "      <td id=\"T_819f4_row7_col4\" class=\"data row7 col4\" >0.50 ['package_summary', 'change_suggester', 'file_analyzer', 'localizer', 'api']</td>\n",
       "      <td id=\"T_819f4_row7_col5\" class=\"data row7 col5\" >0.50 ['package_summary', 'file_analyzer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_819f4_level0_row8\" class=\"row_heading level0 row8\" >9</th>\n",
       "      <td id=\"T_819f4_row8_col0\" class=\"data row8 col0\" >Retrieval based localization</td>\n",
       "      <td id=\"T_819f4_row8_col1\" class=\"data row8 col1\" >['localizer', 'project', 'api', 'model_configuration_manager']</td>\n",
       "      <td id=\"T_819f4_row8_col2\" class=\"data row8 col2\" >0.95 ['localizer', 'change_suggester', 'project', 'api', 'model_configuration_manager']</td>\n",
       "      <td id=\"T_819f4_row8_col3\" class=\"data row8 col3\" >0.50 ['localizer', 'change_suggester', 'api', 'listener_core', 'package_summary']</td>\n",
       "      <td id=\"T_819f4_row8_col4\" class=\"data row8 col4\" >0.75 ['localizer', 'change_suggester', 'api', 'project', 'listener_core']</td>\n",
       "      <td id=\"T_819f4_row8_col5\" class=\"data row8 col5\" >0.75 ['localizer', 'api', 'onboard_agent', 'project']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_819f4_level0_row9\" class=\"row_heading level0 row9\" >10</th>\n",
       "      <td id=\"T_819f4_row9_col0\" class=\"data row9 col0\" >Checkpoint</td>\n",
       "      <td id=\"T_819f4_row9_col1\" class=\"data row9 col1\" >['project']</td>\n",
       "      <td id=\"T_819f4_row9_col2\" class=\"data row9 col2\" >1.00 ['project', 'onboard_agent', 'model_configuration_manager', 'api', 'listener_core']</td>\n",
       "      <td id=\"T_819f4_row9_col3\" class=\"data row9 col3\" >0.40 ['api', 'onboard_agent', 'listener_core', 'project', 'localizer']</td>\n",
       "      <td id=\"T_819f4_row9_col4\" class=\"data row9 col4\" >0.80 ['onboard_agent', 'project', 'api', 'flask_server', 'listener_core']</td>\n",
       "      <td id=\"T_819f4_row9_col5\" class=\"data row9 col5\" >1.00 ['project']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_819f4_level0_row10\" class=\"row_heading level0 row10\" >11</th>\n",
       "      <td id=\"T_819f4_row10_col0\" class=\"data row10 col0\" >More tolerance for package name during file fetch</td>\n",
       "      <td id=\"T_819f4_row10_col1\" class=\"data row10 col1\" >['project']</td>\n",
       "      <td id=\"T_819f4_row10_col2\" class=\"data row10 col2\" >1.00 ['project', 'change_suggester', 'localizer', 'package_summary', 'model_configuration_manager']</td>\n",
       "      <td id=\"T_819f4_row10_col3\" class=\"data row10 col3\" >0.00 ['localizer', 'change_suggester', 'listener_core', 'api', 'package_summary']</td>\n",
       "      <td id=\"T_819f4_row10_col4\" class=\"data row10 col4\" >0.60 ['localizer', 'change_suggester', 'project', 'listener_core', 'project_info']</td>\n",
       "      <td id=\"T_819f4_row10_col5\" class=\"data row10 col5\" >1.00 ['project', 'localizer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_819f4_level0_row11\" class=\"row_heading level0 row11\" >12</th>\n",
       "      <td id=\"T_819f4_row11_col0\" class=\"data row11 col0\" >Override top-n[packages|files] configs at project level</td>\n",
       "      <td id=\"T_819f4_row11_col1\" class=\"data row11 col1\" >['project_info', 'localizer', 'change_suggester', 'project']</td>\n",
       "      <td id=\"T_819f4_row11_col2\" class=\"data row11 col2\" >0.95 ['localizer', 'change_suggester', 'model_configuration_manager', 'project', 'project_info']</td>\n",
       "      <td id=\"T_819f4_row11_col3\" class=\"data row11 col3\" >0.95 ['localizer', 'change_suggester', 'listener_core', 'project_info', 'project']</td>\n",
       "      <td id=\"T_819f4_row11_col4\" class=\"data row11 col4\" >1.00 ['change_suggester', 'localizer', 'project', 'project_info', 'model_configuration_manager']</td>\n",
       "      <td id=\"T_819f4_row11_col5\" class=\"data row11 col5\" >0.75 ['localizer', 'change_suggester', 'project_info']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_819f4_level0_row12\" class=\"row_heading level0 row12\" >13</th>\n",
       "      <td id=\"T_819f4_row12_col0\" class=\"data row12 col0\" >Exclude empty files from semantic analysis</td>\n",
       "      <td id=\"T_819f4_row12_col1\" class=\"data row12 col1\" >['project', 'file_analyzer']</td>\n",
       "      <td id=\"T_819f4_row12_col2\" class=\"data row12 col2\" >1.00 ['project', 'file_analyzer', 'change_suggester', 'localizer', 'listener_core']</td>\n",
       "      <td id=\"T_819f4_row12_col3\" class=\"data row12 col3\" >0.50 ['file_analyzer', 'change_suggester', 'localizer', 'package_summary', 'file_count']</td>\n",
       "      <td id=\"T_819f4_row12_col4\" class=\"data row12 col4\" >0.80 ['file_analyzer', 'change_suggester', 'file_count', 'project', 'localizer']</td>\n",
       "      <td id=\"T_819f4_row12_col5\" class=\"data row12 col5\" >0.50 ['file_analyzer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_819f4_level0_row13\" class=\"row_heading level0 row13\" >14</th>\n",
       "      <td id=\"T_819f4_row13_col0\" class=\"data row13 col0\" >Error while saving a check-point</td>\n",
       "      <td id=\"T_819f4_row13_col1\" class=\"data row13 col1\" >['project']</td>\n",
       "      <td id=\"T_819f4_row13_col2\" class=\"data row13 col2\" >1.00 ['project', 'onboard_agent', 'project_manager', 'project_info', 'listener_core']</td>\n",
       "      <td id=\"T_819f4_row13_col3\" class=\"data row13 col3\" >1.00 ['project', 'onboard_agent', 'listener_core', 'project_info', 'project_manager']</td>\n",
       "      <td id=\"T_819f4_row13_col4\" class=\"data row13 col4\" >1.00 ['project', 'onboard_agent', 'listener_core', 'project_info', 'project_manager']</td>\n",
       "      <td id=\"T_819f4_row13_col5\" class=\"data row13 col5\" >1.00 ['project', 'project_manager']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_819f4_level0_row14\" class=\"row_heading level0 row14\" >15</th>\n",
       "      <td id=\"T_819f4_row14_col0\" class=\"data row14 col0\" >Error while onboarding a new project</td>\n",
       "      <td id=\"T_819f4_row14_col1\" class=\"data row14 col1\" >['project', 'onboard_agent', 'listener_core', 'project_manager']</td>\n",
       "      <td id=\"T_819f4_row14_col2\" class=\"data row14 col2\" >0.95 ['onboard_agent', 'lambda_function', 'project', 'project_manager', 'listener_core']</td>\n",
       "      <td id=\"T_819f4_row14_col3\" class=\"data row14 col3\" >0.75 ['onboard_agent', 'listener_core', 'project', 'lambda_function', 'project_info']</td>\n",
       "      <td id=\"T_819f4_row14_col4\" class=\"data row14 col4\" >0.75 ['onboard_agent', 'project', 'listener_core', 'lambda_function', 'flask_server']</td>\n",
       "      <td id=\"T_819f4_row14_col5\" class=\"data row14 col5\" >0.75 ['listener_core', 'project', 'project_manager']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_819f4_level0_row15\" class=\"row_heading level0 row15\" >16</th>\n",
       "      <td id=\"T_819f4_row15_col0\" class=\"data row15 col0\" >Ignore comment if issue state is closed</td>\n",
       "      <td id=\"T_819f4_row15_col1\" class=\"data row15 col1\" >['listener_core']</td>\n",
       "      <td id=\"T_819f4_row15_col2\" class=\"data row15 col2\" >1.00 ['listener_core', 'project', 'issue_analyzer', 'change_suggester', 'lambda_function']</td>\n",
       "      <td id=\"T_819f4_row15_col3\" class=\"data row15 col3\" >1.00 ['listener_core', 'issue_analyzer', 'lambda_function', 'change_suggester', 'project']</td>\n",
       "      <td id=\"T_819f4_row15_col4\" class=\"data row15 col4\" >1.00 ['listener_core', 'issue_analyzer', 'project', 'change_suggester', 'lambda_function']</td>\n",
       "      <td id=\"T_819f4_row15_col5\" class=\"data row15 col5\" >1.00 ['listener_core', 'issue_analyzer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_819f4_level0_row16\" class=\"row_heading level0 row16\" >17</th>\n",
       "      <td id=\"T_819f4_row16_col0\" class=\"data row16 col0\" >Long running events</td>\n",
       "      <td id=\"T_819f4_row16_col1\" class=\"data row16 col1\" >['lambda_function', 'flask_server', 'listener_core']</td>\n",
       "      <td id=\"T_819f4_row16_col2\" class=\"data row16 col2\" >1.00 ['listener_core', 'flask_server', 'lambda_function', 'project', 'onboard_agent']</td>\n",
       "      <td id=\"T_819f4_row16_col3\" class=\"data row16 col3\" >1.00 ['lambda_function', 'listener_core', 'flask_server', 'onboard_agent', 'project']</td>\n",
       "      <td id=\"T_819f4_row16_col4\" class=\"data row16 col4\" >1.00 ['lambda_function', 'flask_server', 'listener_core', 'onboard_agent', 'project']</td>\n",
       "      <td id=\"T_819f4_row16_col5\" class=\"data row16 col5\" >1.00 ['lambda_function', 'flask_server', 'listener_core', 'onboard_agent']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_819f4_level0_row17\" class=\"row_heading level0 row17\" >18</th>\n",
       "      <td id=\"T_819f4_row17_col0\" class=\"data row17 col0\" >allow issues to be labeled off-limit for the agent</td>\n",
       "      <td id=\"T_819f4_row17_col1\" class=\"data row17 col1\" >['project']</td>\n",
       "      <td id=\"T_819f4_row17_col2\" class=\"data row17 col2\" >0.80 ['listener_core', 'project', 'localizer', 'issue_analyzer', 'change_suggester']</td>\n",
       "      <td id=\"T_819f4_row17_col3\" class=\"data row17 col3\" >0.00 ['listener_core', 'issue_analyzer', 'localizer', 'onboard_agent', 'change_suggester']</td>\n",
       "      <td id=\"T_819f4_row17_col4\" class=\"data row17 col4\" >0.60 ['listener_core', 'issue_analyzer', 'project', 'localizer', 'change_suggester']</td>\n",
       "      <td id=\"T_819f4_row17_col5\" class=\"data row17 col5\" >0.00 ['listener_core', 'issue_analyzer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_819f4_level0_row18\" class=\"row_heading level0 row18\" >19</th>\n",
       "      <td id=\"T_819f4_row18_col0\" class=\"data row18 col0\" >decide to respond to an issue</td>\n",
       "      <td id=\"T_819f4_row18_col1\" class=\"data row18 col1\" >['listener_core', 'model_configuration_manager', 'localizer', 'project', 'api']</td>\n",
       "      <td id=\"T_819f4_row18_col2\" class=\"data row18 col2\" >0.60 ['localizer', 'change_suggester', 'listener_core', 'project', 'issue_analyzer']</td>\n",
       "      <td id=\"T_819f4_row18_col3\" class=\"data row18 col3\" >0.60 ['listener_core', 'issue_analyzer', 'change_suggester', 'localizer', 'api']</td>\n",
       "      <td id=\"T_819f4_row18_col4\" class=\"data row18 col4\" >0.60 ['change_suggester', 'issue_analyzer', 'localizer', 'listener_core', 'project']</td>\n",
       "      <td id=\"T_819f4_row18_col5\" class=\"data row18 col5\" >0.40 ['listener_core', 'api', 'issue_analyzer', 'change_suggester', 'flask_server']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_819f4_level0_row19\" class=\"row_heading level0 row19\" >20</th>\n",
       "      <td id=\"T_819f4_row19_col0\" class=\"data row19 col0\" >domain / project memories</td>\n",
       "      <td id=\"T_819f4_row19_col1\" class=\"data row19 col1\" >['listener_core', 'model_configuration_manager', 'project', 'localizer', 'change_suggester']</td>\n",
       "      <td id=\"T_819f4_row19_col2\" class=\"data row19 col2\" >0.80 ['localizer', 'change_suggester', 'project', 'issue_analyzer', 'listener_core']</td>\n",
       "      <td id=\"T_819f4_row19_col3\" class=\"data row19 col3\" >0.60 ['change_suggester', 'listener_core', 'issue_analyzer', 'localizer', 'onboard_agent']</td>\n",
       "      <td id=\"T_819f4_row19_col4\" class=\"data row19 col4\" >0.80 ['change_suggester', 'localizer', 'issue_analyzer', 'project', 'listener_core']</td>\n",
       "      <td id=\"T_819f4_row19_col5\" class=\"data row19 col5\" >0.40 ['issue_analyzer', 'listener_core', 'api', 'model_configuration_manager']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_819f4_level0_row20\" class=\"row_heading level0 row20\" >21</th>\n",
       "      <td id=\"T_819f4_row20_col0\" class=\"data row20 col0\" >memories api</td>\n",
       "      <td id=\"T_819f4_row20_col1\" class=\"data row20 col1\" >['flask_server', 'lambda_function', 'project', 'listener_core']</td>\n",
       "      <td id=\"T_819f4_row20_col2\" class=\"data row20 col2\" >0.50 ['project', 'listener_core', 'issue_analyzer', 'change_suggester', 'project_manager']</td>\n",
       "      <td id=\"T_819f4_row20_col3\" class=\"data row20 col3\" >0.50 ['listener_core', 'onboard_agent', 'project', 'issue_analyzer', 'project_info']</td>\n",
       "      <td id=\"T_819f4_row20_col4\" class=\"data row20 col4\" >0.50 ['listener_core', 'project', 'issue_analyzer', 'change_suggester', 'localizer']</td>\n",
       "      <td id=\"T_819f4_row20_col5\" class=\"data row20 col5\" >0.50 ['flask_server', 'listener_core', 'project_manager']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_819f4_level0_row21\" class=\"row_heading level0 row21\" >22</th>\n",
       "      <td id=\"T_819f4_row21_col0\" class=\"data row21 col0\" >proactive creation of package-detail document</td>\n",
       "      <td id=\"T_819f4_row21_col1\" class=\"data row21 col1\" >['project']</td>\n",
       "      <td id=\"T_819f4_row21_col2\" class=\"data row21 col2\" >0.80 ['package_summary', 'project', 'localizer', 'change_suggester', 'issue_analyzer']</td>\n",
       "      <td id=\"T_819f4_row21_col3\" class=\"data row21 col3\" >0.80 ['localizer', 'project', 'package_summary', 'listener_core', 'project_info']</td>\n",
       "      <td id=\"T_819f4_row21_col4\" class=\"data row21 col4\" >1.00 ['project', 'package_summary', 'localizer', 'project_info', 'change_suggester']</td>\n",
       "      <td id=\"T_819f4_row21_col5\" class=\"data row21 col5\" >1.00 ['project', 'project_manager', 'localizer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_819f4_level0_row22\" class=\"row_heading level0 row22\" >23</th>\n",
       "      <td id=\"T_819f4_row22_col0\" class=\"data row22 col0\" >proactive creation of package-detail document</td>\n",
       "      <td id=\"T_819f4_row22_col1\" class=\"data row22 col1\" >['project', 'localizer', 'model_configuration_manager']</td>\n",
       "      <td id=\"T_819f4_row22_col2\" class=\"data row22 col2\" >0.67 ['package_summary', 'project', 'localizer', 'change_suggester', 'issue_analyzer']</td>\n",
       "      <td id=\"T_819f4_row22_col3\" class=\"data row22 col3\" >0.67 ['localizer', 'project', 'package_summary', 'listener_core', 'project_info']</td>\n",
       "      <td id=\"T_819f4_row22_col4\" class=\"data row22 col4\" >0.67 ['project', 'package_summary', 'localizer', 'project_info', 'change_suggester']</td>\n",
       "      <td id=\"T_819f4_row22_col5\" class=\"data row22 col5\" >0.33 ['project', 'project_manager', 'project_info']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_819f4_level0_row23\" class=\"row_heading level0 row23\" >24</th>\n",
       "      <td id=\"T_819f4_row23_col0\" class=\"data row23 col0\" >cover all files in the repo (not just code)</td>\n",
       "      <td id=\"T_819f4_row23_col1\" class=\"data row23 col1\" >['project', 'localizer', 'model_configuration_manager', 'listener_core']</td>\n",
       "      <td id=\"T_819f4_row23_col2\" class=\"data row23 col2\" >0.75 ['project', 'change_suggester', 'localizer', 'listener_core', 'project_info']</td>\n",
       "      <td id=\"T_819f4_row23_col3\" class=\"data row23 col3\" >0.75 ['change_suggester', 'localizer', 'listener_core', 'project', 'issue_analyzer']</td>\n",
       "      <td id=\"T_819f4_row23_col4\" class=\"data row23 col4\" >0.75 ['change_suggester', 'localizer', 'project', 'listener_core', 'file_count']</td>\n",
       "      <td id=\"T_819f4_row23_col5\" class=\"data row23 col5\" >0.00 ['file_analyzer', 'package_summary', 'change_suggester']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_819f4_level0_row24\" class=\"row_heading level0 row24\" >25</th>\n",
       "      <td id=\"T_819f4_row24_col0\" class=\"data row24 col0\" >Refactor localization</td>\n",
       "      <td id=\"T_819f4_row24_col1\" class=\"data row24 col1\" >['localizer', 'project', 'listener_core', 'api', 'model_configuration_manager']</td>\n",
       "      <td id=\"T_819f4_row24_col2\" class=\"data row24 col2\" >0.80 ['change_suggester', 'localizer', 'project', 'listener_core', 'model_configuration_manager']</td>\n",
       "      <td id=\"T_819f4_row24_col3\" class=\"data row24 col3\" >0.60 ['change_suggester', 'localizer', 'listener_core', 'issue_analyzer', 'api']</td>\n",
       "      <td id=\"T_819f4_row24_col4\" class=\"data row24 col4\" >0.60 ['change_suggester', 'localizer', 'project', 'listener_core', 'issue_analyzer']</td>\n",
       "      <td id=\"T_819f4_row24_col5\" class=\"data row24 col5\" >0.20 ['localizer', 'file_analyzer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_819f4_level0_row25\" class=\"row_heading level0 row25\" >26</th>\n",
       "      <td id=\"T_819f4_row25_col0\" class=\"data row25 col0\" >Score</td>\n",
       "      <td id=\"T_819f4_row25_col1\" class=\"data row25 col1\" ></td>\n",
       "      <td id=\"T_819f4_row25_col2\" class=\"data row25 col2\" >85.13%</td>\n",
       "      <td id=\"T_819f4_row25_col3\" class=\"data row25 col3\" >66.60%</td>\n",
       "      <td id=\"T_819f4_row25_col4\" class=\"data row25 col4\" >78.80%</td>\n",
       "      <td id=\"T_819f4_row25_col5\" class=\"data row25 col5\" >68.40%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1744d0560>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a copy of the DataFrame for display purposes\n",
    "display_df = evaluation_results.copy()\n",
    "\n",
    "# Set the index to start from 1\n",
    "display_df.index = display_df.index + 1\n",
    "\n",
    "# Apply left alignment to all columns, including headers\n",
    "df_style = display_df.style \\\n",
    "    .set_table_attributes(\"style='width:100%'\") \\\n",
    "    .set_properties(**{'text-align': 'left'}) \\\n",
    "    .set_table_styles([{\n",
    "        'selector': 'th',\n",
    "        'props': [('text-align', 'left')]\n",
    "    }])\n",
    "\n",
    "df_style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleanup the temporary directory for combined files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(combined_docs_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
