{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate localization strategies\n",
    "\n",
    "This notebook does a comparative evaluation of different localization strategies.\n",
    "- Defines a base interface for localization\n",
    "- Implements a few localization strategies\n",
    "- Defines an evaluator that runs a test suite on those localization strategies\n",
    "- Evaluator dumps the results in a pandas dataframe\n",
    "- Uses Milvus as the vector database\n",
    "- Uses OpenAI's embeddings model\n",
    "- Uses langchain's abstractions for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from typing import Dict, List, Tuple\n",
    "from abc import ABC, abstractmethod\n",
    "from langchain_core.documents import Document\n",
    "from langchain_milvus import Milvus\n",
    "\n",
    "from se_agent.localizer import localize_issue\n",
    "from se_agent.project import Project\n",
    "from se_agent.project_manager import ProjectManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base interface for localization strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Strategy(ABC):\n",
    "    @abstractmethod\n",
    "    def localize(self, issue: Dict[str, str], top_n: int) -> List[Tuple[str, str]]:\n",
    "        \"\"\"\n",
    "        Localizes the issue to a set of relevant packages and files.\n",
    "\n",
    "        Args:\n",
    "            issue (Dict[str, str]): A dictionary containing issue details with at least:\n",
    "                - `title` (str): The title of the issue.\n",
    "                - `description` (str): The detailed description of the issue.\n",
    "            top_n (int): The maximum number of localization results to return.\n",
    "\n",
    "        Returns:\n",
    "            List[Tuple[str, str]]: A list of tuples representing relevant localization results,\n",
    "                each containing `package` (str) and `file` (str).\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic vector search strategy\n",
    "\n",
    "This implements a simple semantic vector search strategy. It uses Milvus as the vector database and OpenAI's embeddings model. Implementation may be used as-is for multiple strategies by feeding in different types of sources. E.g.,\n",
    "- **Code file embeddings**: Providing a `source_dir` pointing to code files will directly embed code\n",
    "- **Code semantics embeddings**: Providing a `source_dir` pointing to semantic descriptions of code files will embed code semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticVectorSearchStrategy(Strategy):\n",
    "    def __init__(self, source_dir: str, root_package_name: str, embeddings, strategy_name: str):\n",
    "        self.strategy_name = strategy_name\n",
    "        self.vector_store = self.create_vector_store(source_dir, root_package_name, embeddings)\n",
    "\n",
    "    def create_vector_store(self, folder_path: str, root_package_name: str, embeddings) -> Milvus:\n",
    "        \"\"\"Creates a Milvus vector store from the files in the specified folder.\"\"\"\n",
    "        documents = self.create_documents(folder_path, root_package_name)\n",
    "        with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as tmp_file:\n",
    "            uri = tmp_file.name\n",
    "        return Milvus.from_documents(\n",
    "            documents,\n",
    "            embeddings,\n",
    "            collection_name=root_package_name,\n",
    "            connection_args={\"uri\": uri},\n",
    "        )\n",
    "    \n",
    "    def create_documents(self, folder_path: str, root_package_name: str) -> List[Document]:\n",
    "        \"\"\"Create a list of Document instances from the files in the specified folder.\"\"\"\n",
    "        documents = []\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, \"r\") as f:\n",
    "                    page_content = f.read()\n",
    "                if not page_content.strip():\n",
    "                    continue\n",
    "                filename = file.split('.')[0]\n",
    "                relative_path = os.path.relpath(root, folder_path)\n",
    "                package = (f\"{root_package_name}/{relative_path.replace(os.sep, '/')}\"\n",
    "                           if relative_path != \".\" else root_package_name)\n",
    "                document = Document(\n",
    "                    page_content=page_content,\n",
    "                    metadata={\"file\": filename, \"package\": package}\n",
    "                )\n",
    "                documents.append(document)\n",
    "        return documents\n",
    "\n",
    "    def localize(self, issue: Dict[str, str], top_n: int) -> List[Tuple[str, str]]:\n",
    "        query_string = f\"{issue['title']}: {issue['description']}\"\n",
    "        results = self.vector_store.similarity_search(query_string, k=top_n)\n",
    "        return [(res.metadata[\"package\"], res.metadata[\"file\"]) for res in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical localization strategy\n",
    "\n",
    "Instead of semantic vector search, this strategy uses the completion API to generate localization results. This requires inlining the context. Using all the files in the repository as context, far-exceed the permitted token limits of the completion API. Therefore, it uses generated semantic summaries of the code files as context. However, for large repositories, and depending on the model used, this may still exceed the token limits. Therefore, it also generates higher-level summaries at the level of packages. Let us assume that the aggregated package summaries are within the token limits. The strategy operates as follows:\n",
    "\n",
    "- **Package level**: Given an issue, it first identifies the package that are relevant to the issue query belongs to, using packages summaries in the inline context.\n",
    "- **File level**: It then identifies the files within the package that are relevant to the issue query, using file summaries for the relevant packages in the inline context.\n",
    "\n",
    "This strategy is more expensive than the semantic vector search strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalLocalizationStrategy(Strategy):\n",
    "    def __init__(self, project: Project, strategy_name: str = \"Hierarchical Completion\"):\n",
    "        self.project = project\n",
    "        self.strategy_name = strategy_name\n",
    "\n",
    "    def localize(self, issue: Dict[str, str], top_n: int) -> List[Tuple[str, str]]:\n",
    "        \"\"\"\n",
    "        Localizes an issue to specific files by first identifying relevant packages\n",
    "        and then narrowing down to specific files in those packages.\n",
    "        \"\"\"\n",
    "        # issue conversation\n",
    "        issue_conversation = {\n",
    "            \"title\": issue[\"title\"],\n",
    "            \"conversation\": [{'role': 'user', 'content': f'Issue: {issue[\"title\"]}\\n\\nDescription: {issue[\"description\"]}'}]\n",
    "        }\n",
    "\n",
    "        # Localize the issue using the hierarchical approach\n",
    "        localization_suggestions = localize_issue(self.project, issue, issue_conversation)\n",
    "\n",
    "        if localization_suggestions is None:\n",
    "            return []  # If localization fails, return an empty list\n",
    "\n",
    "        # Format the results as (package, file) tuples, sorted by confidence\n",
    "        return [(suggestion.package, os.path.splitext(suggestion.file)[0]) for suggestion in localization_suggestions[:top_n]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Iterator\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "class Issue:\n",
    "    def __init__(self, id: str, title: str, content: str, expected_results: List[str]):\n",
    "        self.id = id\n",
    "        self.title = title\n",
    "        self.content = content\n",
    "        self.expected_results = expected_results\n",
    "\n",
    "    def to_dict(self) -> Dict[str, str]:\n",
    "        \"\"\"Returns the issue data as a dictionary for easy access.\"\"\"\n",
    "        return {\"title\": self.title, \"description\": self.content}\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, yaml_path: str):\n",
    "        self.yaml_dir = os.path.dirname(yaml_path)  # Get the directory containing the YAML file\n",
    "        with open(yaml_path, 'r') as f:\n",
    "            data = yaml.safe_load(f)\n",
    "        self.test_cases = data[\"test_cases\"]\n",
    "\n",
    "    def __iter__(self) -> Iterator[Issue]:\n",
    "        \"\"\"Allows iteration over Issue instances created from test cases.\"\"\"\n",
    "        for case in self.test_cases:\n",
    "            # Construct the full path to the markdown file\n",
    "            full_path = os.path.join(self.yaml_dir, case[\"filepath\"])\n",
    "            # Load the content from the markdown file\n",
    "            with open(full_path, 'r') as f:\n",
    "                content = f.read()\n",
    "            # Create an Issue instance for each test case\n",
    "            yield Issue(\n",
    "                id=case[\"id\"],\n",
    "                title=case[\"title\"],\n",
    "                content=content,\n",
    "                expected_results=case[\"expected_results\"]\n",
    "            )\n",
    "\n",
    "dataset = Dataset(\"test/dataset.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalizationEvaluator:\n",
    "    def __init__(self, dataset: Dataset, strategies_to_evaluate: List[Strategy]):\n",
    "        self.dataset = dataset\n",
    "        self.strategies = strategies_to_evaluate\n",
    "\n",
    "    def calculate_score(self, expected_results: List[str], actual_results: List[str]) -> float:\n",
    "        \"\"\"Calculates the score with distance-based penalties for expected results outside the top-k.\"\"\"\n",
    "        score = 1.0  # Start with a perfect score of 1\n",
    "\n",
    "        for expected in expected_results:\n",
    "            if expected in actual_results:\n",
    "                index = actual_results.index(expected)\n",
    "                # Check if expected item is within the top-k\n",
    "                if index >= len(expected_results):\n",
    "                    # Distance-based partial penalty if it's outside top-k but present in results\n",
    "                    distance_factor = index - len(expected_results) + 1\n",
    "                    penalty = (1 / len(expected_results)) * distance_factor * 0.2\n",
    "                    score -= penalty\n",
    "            else:\n",
    "                # Full penalty if expected item is missing altogether\n",
    "                score -= 1 / len(expected_results)\n",
    "\n",
    "        return max(score, 0)  # Ensure score doesn't go below 0\n",
    "\n",
    "    def evaluate(self) -> pd.DataFrame:\n",
    "        \"\"\"Evaluates each strategy on all test issues and returns a DataFrame with results and scores.\"\"\"\n",
    "        df = pd.DataFrame(columns=[\"Issue Title\", \"Expected Results\"] + [f\"Results ({strategy.strategy_name})\" for strategy in self.strategies])\n",
    "\n",
    "        # Dictionary to store total scores per strategy\n",
    "        total_scores = {strategy.strategy_name: 0 for strategy in self.strategies}\n",
    "\n",
    "        # Iterate over each Issue in the dataset\n",
    "        for issue in self.dataset:\n",
    "            issue_data = {\"title\": issue.title, \"description\": issue.content}  # Prepare data for localization\n",
    "            row_data = {\n",
    "                \"Issue Title\": issue.title,\n",
    "                \"Expected Results\": issue.expected_results\n",
    "            }\n",
    "\n",
    "            # Calculate and store results and formatted score+results for each strategy\n",
    "            for strategy in self.strategies:\n",
    "                actual_results = [res[1] for res in strategy.localize(issue_data, top_n=5)]\n",
    "                score = self.calculate_score(issue.expected_results, actual_results)\n",
    "                total_scores[strategy.strategy_name] += score  # Accumulate score for total\n",
    "\n",
    "                # Format results with score as requested\n",
    "                formatted_result = f\"{score:.2f} {actual_results}\"\n",
    "                row_data[f\"Results ({strategy.strategy_name})\"] = formatted_result\n",
    "\n",
    "            # Append row data to DataFrame\n",
    "            df = pd.concat([df, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "        # Append total scores row to DataFrame\n",
    "        total_row = {\"Issue Title\": \"Total\", \"Expected Results\": \"\"}\n",
    "        for strategy in self.strategies:\n",
    "            total_row[f\"Results ({strategy.strategy_name})\"] = f\"{total_scores[strategy.strategy_name]:.2f}\"\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame([total_row])], ignore_index=True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_store = \"/Users/pdhoolia/projects-store\"\n",
    "repo_full_name = \"pdhoolia/se-agent\"\n",
    "src_dir = \"se_agent\"\n",
    "\n",
    "code_dir = os.path.join(projects_store, repo_full_name, \"repo\", src_dir)\n",
    "code_semantics_dir = os.path.join(projects_store, repo_full_name, \"metadata\", \"package_details\")\n",
    "\n",
    "project_manager = ProjectManager(projects_store)\n",
    "project_info = project_manager.get_project(repo_full_name)\n",
    "project = Project(os.getenv(\"GITHUB_TOKEN\"), projects_store, project_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create combinded semantic summary + Code files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary directory for the combined documents\n",
    "combined_docs_dir = tempfile.mkdtemp()\n",
    "\n",
    "# Iterate over the semantic summaries and combine with corresponding code files\n",
    "for root, _, files in os.walk(code_semantics_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".md\"):\n",
    "            filename_without_extn = file.split('.')[0]\n",
    "            summary_file_path = os.path.join(root, file)\n",
    "            # Get corresponding code file path\n",
    "            relative_path = os.path.relpath(root, code_semantics_dir)\n",
    "            code_file_path = os.path.join(code_dir, relative_path, f\"{filename_without_extn}.py\")\n",
    "            \n",
    "            # Only proceed if the code file exists\n",
    "            if os.path.exists(code_file_path):\n",
    "                # Read content from both summary and code files\n",
    "                with open(summary_file_path, \"r\") as summary_file:\n",
    "                    semantic_summary_content = summary_file.read()\n",
    "                with open(code_file_path, \"r\") as code_file:\n",
    "                    code_content = code_file.read()\n",
    "                \n",
    "                # Combine the contents\n",
    "                combined_content = f\"# Semantic summary\\n\\n{semantic_summary_content}\\n\\n# Code\\n\\n```python\\n{code_content}\\n```\"\n",
    "                \n",
    "                # Define path for the combined document in the temporary folder\n",
    "                combined_file_dir = os.path.join(combined_docs_dir, relative_path)\n",
    "                os.makedirs(combined_file_dir, exist_ok=True)\n",
    "                combined_file_path = os.path.join(combined_file_dir, f\"{filename_without_extn}.md\")\n",
    "                \n",
    "                # Save the combined content\n",
    "                with open(combined_file_path, \"w\") as combined_file:\n",
    "                    combined_file.write(combined_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pdhoolia/fun/se-agent/.conda/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-large-en\"\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strategies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "code_file_embeddings = SemanticVectorSearchStrategy(code_dir, src_dir, embeddings, strategy_name=\"Code File Embeddings\")\n",
    "code_semantics_embeddings = SemanticVectorSearchStrategy(code_semantics_dir, src_dir, embeddings, strategy_name=\"Code Semantics Embeddings\")\n",
    "combined_embeddings = SemanticVectorSearchStrategy(combined_docs_dir, src_dir, embeddings, strategy_name=\"Combined Embeddings\")\n",
    "# hierarchical_strategy = HierarchicalLocalizationStrategy(project, strategy_name=\"Hierarchical Localization\")\n",
    "\n",
    "strategies_to_evaluate = [code_file_embeddings, code_semantics_embeddings, combined_embeddings]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = LocalizationEvaluator(\n",
    "    dataset=dataset,\n",
    "    strategies_to_evaluate=strategies_to_evaluate\n",
    ")\n",
    "\n",
    "evaluation_results = evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_81949 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_81949_row0_col0, #T_81949_row0_col1, #T_81949_row0_col2, #T_81949_row0_col3, #T_81949_row0_col4, #T_81949_row1_col0, #T_81949_row1_col1, #T_81949_row1_col2, #T_81949_row1_col3, #T_81949_row1_col4, #T_81949_row2_col0, #T_81949_row2_col1, #T_81949_row2_col2, #T_81949_row2_col3, #T_81949_row2_col4, #T_81949_row3_col0, #T_81949_row3_col1, #T_81949_row3_col2, #T_81949_row3_col3, #T_81949_row3_col4, #T_81949_row4_col0, #T_81949_row4_col1, #T_81949_row4_col2, #T_81949_row4_col3, #T_81949_row4_col4, #T_81949_row5_col0, #T_81949_row5_col1, #T_81949_row5_col2, #T_81949_row5_col3, #T_81949_row5_col4, #T_81949_row6_col0, #T_81949_row6_col1, #T_81949_row6_col2, #T_81949_row6_col3, #T_81949_row6_col4, #T_81949_row7_col0, #T_81949_row7_col1, #T_81949_row7_col2, #T_81949_row7_col3, #T_81949_row7_col4, #T_81949_row8_col0, #T_81949_row8_col1, #T_81949_row8_col2, #T_81949_row8_col3, #T_81949_row8_col4, #T_81949_row9_col0, #T_81949_row9_col1, #T_81949_row9_col2, #T_81949_row9_col3, #T_81949_row9_col4, #T_81949_row10_col0, #T_81949_row10_col1, #T_81949_row10_col2, #T_81949_row10_col3, #T_81949_row10_col4, #T_81949_row11_col0, #T_81949_row11_col1, #T_81949_row11_col2, #T_81949_row11_col3, #T_81949_row11_col4, #T_81949_row12_col0, #T_81949_row12_col1, #T_81949_row12_col2, #T_81949_row12_col3, #T_81949_row12_col4, #T_81949_row13_col0, #T_81949_row13_col1, #T_81949_row13_col2, #T_81949_row13_col3, #T_81949_row13_col4, #T_81949_row14_col0, #T_81949_row14_col1, #T_81949_row14_col2, #T_81949_row14_col3, #T_81949_row14_col4, #T_81949_row15_col0, #T_81949_row15_col1, #T_81949_row15_col2, #T_81949_row15_col3, #T_81949_row15_col4, #T_81949_row16_col0, #T_81949_row16_col1, #T_81949_row16_col2, #T_81949_row16_col3, #T_81949_row16_col4, #T_81949_row17_col0, #T_81949_row17_col1, #T_81949_row17_col2, #T_81949_row17_col3, #T_81949_row17_col4, #T_81949_row18_col0, #T_81949_row18_col1, #T_81949_row18_col2, #T_81949_row18_col3, #T_81949_row18_col4, #T_81949_row19_col0, #T_81949_row19_col1, #T_81949_row19_col2, #T_81949_row19_col3, #T_81949_row19_col4, #T_81949_row20_col0, #T_81949_row20_col1, #T_81949_row20_col2, #T_81949_row20_col3, #T_81949_row20_col4, #T_81949_row21_col0, #T_81949_row21_col1, #T_81949_row21_col2, #T_81949_row21_col3, #T_81949_row21_col4, #T_81949_row22_col0, #T_81949_row22_col1, #T_81949_row22_col2, #T_81949_row22_col3, #T_81949_row22_col4, #T_81949_row23_col0, #T_81949_row23_col1, #T_81949_row23_col2, #T_81949_row23_col3, #T_81949_row23_col4 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_81949\" style='width:100%'>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_81949_level0_col0\" class=\"col_heading level0 col0\" >Issue Title</th>\n",
       "      <th id=\"T_81949_level0_col1\" class=\"col_heading level0 col1\" >Expected Results</th>\n",
       "      <th id=\"T_81949_level0_col2\" class=\"col_heading level0 col2\" >Results (Code File Embeddings)</th>\n",
       "      <th id=\"T_81949_level0_col3\" class=\"col_heading level0 col3\" >Results (Code Semantics Embeddings)</th>\n",
       "      <th id=\"T_81949_level0_col4\" class=\"col_heading level0 col4\" >Results (Combined Embeddings)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_81949_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_81949_row0_col0\" class=\"data row0 col0\" >Project level override for github token</td>\n",
       "      <td id=\"T_81949_row0_col1\" class=\"data row0 col1\" >['project', 'project_info', 'onboard_agent']</td>\n",
       "      <td id=\"T_81949_row0_col2\" class=\"data row0 col2\" >1.00 ['onboard_agent', 'project_info', 'project', 'listener_core', 'lambda_function']</td>\n",
       "      <td id=\"T_81949_row0_col3\" class=\"data row0 col3\" >0.93 ['project', 'onboard_agent', 'listener_core', 'project_info', 'lambda_function']</td>\n",
       "      <td id=\"T_81949_row0_col4\" class=\"data row0 col4\" >0.93 ['onboard_agent', 'listener_core', 'project_info', 'project', 'lambda_function']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81949_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_81949_row1_col0\" class=\"data row1 col0\" >Retry LLM call on Rate Limit Error</td>\n",
       "      <td id=\"T_81949_row1_col1\" class=\"data row1 col1\" >['retry_with_backoff', 'api']</td>\n",
       "      <td id=\"T_81949_row1_col2\" class=\"data row1 col2\" >1.00 ['retry_with_backoff', 'api', 'file_analyzer', 'change_suggester', 'package_summary']</td>\n",
       "      <td id=\"T_81949_row1_col3\" class=\"data row1 col3\" >1.00 ['retry_with_backoff', 'api', 'model_configuration_manager', 'localizer', 'project_manager']</td>\n",
       "      <td id=\"T_81949_row1_col4\" class=\"data row1 col4\" >1.00 ['retry_with_backoff', 'api', 'model_configuration_manager', 'change_suggester', 'lambda_function']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81949_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_81949_row2_col0\" class=\"data row2 col0\" >Handle issue comments as well</td>\n",
       "      <td id=\"T_81949_row2_col1\" class=\"data row2 col1\" >['listener_core', 'issue_analyzer', 'localizer', 'change_suggester', 'project']</td>\n",
       "      <td id=\"T_81949_row2_col2\" class=\"data row2 col2\" >0.80 ['issue_analyzer', 'change_suggester', 'localizer', 'listener_core', 'lambda_function']</td>\n",
       "      <td id=\"T_81949_row2_col3\" class=\"data row2 col3\" >1.00 ['listener_core', 'issue_analyzer', 'localizer', 'project', 'change_suggester']</td>\n",
       "      <td id=\"T_81949_row2_col4\" class=\"data row2 col4\" >0.80 ['change_suggester', 'listener_core', 'issue_analyzer', 'localizer', 'lambda_function']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81949_level0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "      <td id=\"T_81949_row3_col0\" class=\"data row3 col0\" >Update semantic understanding on code push to the main branch</td>\n",
       "      <td id=\"T_81949_row3_col1\" class=\"data row3 col1\" >['listener_core', 'project', 'file_analyzer', 'package_summary']</td>\n",
       "      <td id=\"T_81949_row3_col2\" class=\"data row3 col2\" >0.50 ['package_summary', 'change_suggester', 'localizer', 'file_analyzer', 'issue_analyzer']</td>\n",
       "      <td id=\"T_81949_row3_col3\" class=\"data row3 col3\" >0.75 ['package_summary', 'project', 'localizer', 'file_analyzer', 'change_suggester']</td>\n",
       "      <td id=\"T_81949_row3_col4\" class=\"data row3 col4\" >0.70 ['package_summary', 'change_suggester', 'localizer', 'project', 'listener_core']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81949_level0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "      <td id=\"T_81949_row4_col0\" class=\"data row4 col0\" >API based onboarding for a new project</td>\n",
       "      <td id=\"T_81949_row4_col1\" class=\"data row4 col1\" >['listener_core', 'flask_server', 'lambda_function', 'project_manager', 'project']</td>\n",
       "      <td id=\"T_81949_row4_col2\" class=\"data row4 col2\" >0.80 ['lambda_function', 'listener_core', 'onboard_agent', 'flask_server', 'project_manager']</td>\n",
       "      <td id=\"T_81949_row4_col3\" class=\"data row4 col3\" >0.80 ['onboard_agent', 'flask_server', 'listener_core', 'lambda_function', 'project']</td>\n",
       "      <td id=\"T_81949_row4_col4\" class=\"data row4 col4\" >0.80 ['onboard_agent', 'listener_core', 'lambda_function', 'flask_server', 'project_manager']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81949_level0_row5\" class=\"row_heading level0 row5\" >6</th>\n",
       "      <td id=\"T_81949_row5_col0\" class=\"data row5 col0\" >Move lambda function within the se_agent package structure</td>\n",
       "      <td id=\"T_81949_row5_col1\" class=\"data row5 col1\" >['lambda_function']</td>\n",
       "      <td id=\"T_81949_row5_col2\" class=\"data row5 col2\" >0.80 ['change_suggester', 'lambda_function', 'package_summary', 'localizer', 'onboard_agent']</td>\n",
       "      <td id=\"T_81949_row5_col3\" class=\"data row5 col3\" >1.00 ['lambda_function', 'package_summary', 'localizer', '__init__', 'model_configuration_manager']</td>\n",
       "      <td id=\"T_81949_row5_col4\" class=\"data row5 col4\" >1.00 ['lambda_function', 'change_suggester', 'localizer', 'package_summary', 'listener_core']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81949_level0_row6\" class=\"row_heading level0 row6\" >7</th>\n",
       "      <td id=\"T_81949_row6_col0\" class=\"data row6 col0\" >Use structured output for semantic summary generation</td>\n",
       "      <td id=\"T_81949_row6_col1\" class=\"data row6 col1\" >['localizer', 'file_analyzer', 'package_summary', 'project']</td>\n",
       "      <td id=\"T_81949_row6_col2\" class=\"data row6 col2\" >0.75 ['package_summary', 'file_analyzer', 'localizer', 'change_suggester', 'api']</td>\n",
       "      <td id=\"T_81949_row6_col3\" class=\"data row6 col3\" >0.95 ['file_analyzer', 'package_summary', 'localizer', 'api', 'project']</td>\n",
       "      <td id=\"T_81949_row6_col4\" class=\"data row6 col4\" >0.75 ['file_analyzer', 'package_summary', 'localizer', 'api', 'change_suggester']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81949_level0_row7\" class=\"row_heading level0 row7\" >8</th>\n",
       "      <td id=\"T_81949_row7_col0\" class=\"data row7 col0\" >Tool based (no LLM) code structure name generation</td>\n",
       "      <td id=\"T_81949_row7_col1\" class=\"data row7 col1\" >['package_summary', 'project']</td>\n",
       "      <td id=\"T_81949_row7_col2\" class=\"data row7 col2\" >0.50 ['package_summary', 'file_analyzer', 'localizer', 'change_suggester', 'api']</td>\n",
       "      <td id=\"T_81949_row7_col3\" class=\"data row7 col3\" >0.80 ['package_summary', 'file_analyzer', 'localizer', 'project', 'change_suggester']</td>\n",
       "      <td id=\"T_81949_row7_col4\" class=\"data row7 col4\" >0.80 ['package_summary', 'file_analyzer', 'change_suggester', 'project', 'localizer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81949_level0_row8\" class=\"row_heading level0 row8\" >9</th>\n",
       "      <td id=\"T_81949_row8_col0\" class=\"data row8 col0\" >Retrieval based localization</td>\n",
       "      <td id=\"T_81949_row8_col1\" class=\"data row8 col1\" >['localizer', 'project', 'api', 'model_configuration_manager']</td>\n",
       "      <td id=\"T_81949_row8_col2\" class=\"data row8 col2\" >0.45 ['localizer', 'change_suggester', 'package_summary', 'file_analyzer', 'api']</td>\n",
       "      <td id=\"T_81949_row8_col3\" class=\"data row8 col3\" >0.75 ['localizer', 'package_summary', 'api', 'project', 'listener_core']</td>\n",
       "      <td id=\"T_81949_row8_col4\" class=\"data row8 col4\" >0.50 ['localizer', 'package_summary', 'api', 'change_suggester', 'listener_core']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81949_level0_row9\" class=\"row_heading level0 row9\" >10</th>\n",
       "      <td id=\"T_81949_row9_col0\" class=\"data row9 col0\" >Checkpoint</td>\n",
       "      <td id=\"T_81949_row9_col1\" class=\"data row9 col1\" >['project']</td>\n",
       "      <td id=\"T_81949_row9_col2\" class=\"data row9 col2\" >0.00 ['listener_core', 'model_configuration_manager', 'lambda_function', 'change_suggester', 'onboard_agent']</td>\n",
       "      <td id=\"T_81949_row9_col3\" class=\"data row9 col3\" >1.00 ['project', 'listener_core', 'onboard_agent', 'model_configuration_manager', 'flask_server']</td>\n",
       "      <td id=\"T_81949_row9_col4\" class=\"data row9 col4\" >1.00 ['project', 'listener_core', 'onboard_agent', 'flask_server', 'model_configuration_manager']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81949_level0_row10\" class=\"row_heading level0 row10\" >11</th>\n",
       "      <td id=\"T_81949_row10_col0\" class=\"data row10 col0\" >More tolerance for package name during file fetch</td>\n",
       "      <td id=\"T_81949_row10_col1\" class=\"data row10 col1\" >['project']</td>\n",
       "      <td id=\"T_81949_row10_col2\" class=\"data row10 col2\" >0.00 ['package_summary', 'project_info', 'project_manager', 'change_suggester', 'localizer']</td>\n",
       "      <td id=\"T_81949_row10_col3\" class=\"data row10 col3\" >0.80 ['localizer', 'project', 'package_summary', 'project_info', 'file_count']</td>\n",
       "      <td id=\"T_81949_row10_col4\" class=\"data row10 col4\" >0.80 ['localizer', 'project', 'change_suggester', 'project_info', 'package_summary']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81949_level0_row11\" class=\"row_heading level0 row11\" >12</th>\n",
       "      <td id=\"T_81949_row11_col0\" class=\"data row11 col0\" >Override top-n[packages|files] configs at project level</td>\n",
       "      <td id=\"T_81949_row11_col1\" class=\"data row11 col1\" >['project_info', 'localizer', 'change_suggester', 'project']</td>\n",
       "      <td id=\"T_81949_row11_col2\" class=\"data row11 col2\" >0.75 ['change_suggester', 'package_summary', 'project_info', 'localizer', 'api']</td>\n",
       "      <td id=\"T_81949_row11_col3\" class=\"data row11 col3\" >0.50 ['api', 'project', 'localizer', 'model_configuration_manager', 'package_summary']</td>\n",
       "      <td id=\"T_81949_row11_col4\" class=\"data row11 col4\" >0.50 ['model_configuration_manager', 'change_suggester', 'project_info', 'package_summary', 'api']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81949_level0_row12\" class=\"row_heading level0 row12\" >13</th>\n",
       "      <td id=\"T_81949_row12_col0\" class=\"data row12 col0\" >Exclude empty files from semantic analysis</td>\n",
       "      <td id=\"T_81949_row12_col1\" class=\"data row12 col1\" >['project', 'file_analyzer']</td>\n",
       "      <td id=\"T_81949_row12_col2\" class=\"data row12 col2\" >0.50 ['file_analyzer', 'change_suggester', 'localizer', 'project_info', 'issue_analyzer']</td>\n",
       "      <td id=\"T_81949_row12_col3\" class=\"data row12 col3\" >0.90 ['file_analyzer', 'localizer', 'project', 'package_summary', 'issue_analyzer']</td>\n",
       "      <td id=\"T_81949_row12_col4\" class=\"data row12 col4\" >0.50 ['file_analyzer', 'issue_analyzer', 'project_info', 'change_suggester', 'localizer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81949_level0_row13\" class=\"row_heading level0 row13\" >14</th>\n",
       "      <td id=\"T_81949_row13_col0\" class=\"data row13 col0\" >Error while saving a check-point</td>\n",
       "      <td id=\"T_81949_row13_col1\" class=\"data row13 col1\" >['project']</td>\n",
       "      <td id=\"T_81949_row13_col2\" class=\"data row13 col2\" >0.80 ['listener_core', 'project', 'project_manager', 'onboard_agent', 'issue_analyzer']</td>\n",
       "      <td id=\"T_81949_row13_col3\" class=\"data row13 col3\" >1.00 ['project', 'localizer', 'project_manager', 'listener_core', 'package_summary']</td>\n",
       "      <td id=\"T_81949_row13_col4\" class=\"data row13 col4\" >1.00 ['project', 'listener_core', 'change_suggester', 'issue_analyzer', 'project_manager']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81949_level0_row14\" class=\"row_heading level0 row14\" >15</th>\n",
       "      <td id=\"T_81949_row14_col0\" class=\"data row14 col0\" >Error while onboarding a new project</td>\n",
       "      <td id=\"T_81949_row14_col1\" class=\"data row14 col1\" >['project', 'onboard_agent', 'listener_core', 'project_manager']</td>\n",
       "      <td id=\"T_81949_row14_col2\" class=\"data row14 col2\" >0.95 ['listener_core', 'onboard_agent', 'project_manager', 'lambda_function', 'project']</td>\n",
       "      <td id=\"T_81949_row14_col3\" class=\"data row14 col3\" >0.75 ['onboard_agent', 'listener_core', 'project', 'flask_server', 'localizer']</td>\n",
       "      <td id=\"T_81949_row14_col4\" class=\"data row14 col4\" >0.70 ['listener_core', 'onboard_agent', 'lambda_function', 'change_suggester', 'project_manager']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81949_level0_row15\" class=\"row_heading level0 row15\" >16</th>\n",
       "      <td id=\"T_81949_row15_col0\" class=\"data row15 col0\" >Ignore comment if issue state is closed</td>\n",
       "      <td id=\"T_81949_row15_col1\" class=\"data row15 col1\" >['listener_core']</td>\n",
       "      <td id=\"T_81949_row15_col2\" class=\"data row15 col2\" >0.40 ['issue_analyzer', 'change_suggester', 'localizer', 'listener_core', 'lambda_function']</td>\n",
       "      <td id=\"T_81949_row15_col3\" class=\"data row15 col3\" >0.60 ['issue_analyzer', 'localizer', 'listener_core', 'change_suggester', '__init__']</td>\n",
       "      <td id=\"T_81949_row15_col4\" class=\"data row15 col4\" >0.60 ['issue_analyzer', 'change_suggester', 'listener_core', 'localizer', 'lambda_function']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81949_level0_row16\" class=\"row_heading level0 row16\" >17</th>\n",
       "      <td id=\"T_81949_row16_col0\" class=\"data row16 col0\" >Long running events</td>\n",
       "      <td id=\"T_81949_row16_col1\" class=\"data row16 col1\" >['lambda_function', 'flask_server', 'listener_core']</td>\n",
       "      <td id=\"T_81949_row16_col2\" class=\"data row16 col2\" >0.93 ['lambda_function', 'flask_server', 'onboard_agent', 'listener_core', 'issue_analyzer']</td>\n",
       "      <td id=\"T_81949_row16_col3\" class=\"data row16 col3\" >1.00 ['listener_core', 'lambda_function', 'flask_server', 'onboard_agent', 'project']</td>\n",
       "      <td id=\"T_81949_row16_col4\" class=\"data row16 col4\" >1.00 ['lambda_function', 'listener_core', 'flask_server', 'onboard_agent', 'project']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81949_level0_row17\" class=\"row_heading level0 row17\" >18</th>\n",
       "      <td id=\"T_81949_row17_col0\" class=\"data row17 col0\" >allow issues to be labeled off-limit for the agent</td>\n",
       "      <td id=\"T_81949_row17_col1\" class=\"data row17 col1\" >['project']</td>\n",
       "      <td id=\"T_81949_row17_col2\" class=\"data row17 col2\" >0.00 ['issue_analyzer', 'change_suggester', 'localizer', 'listener_core', 'lambda_function']</td>\n",
       "      <td id=\"T_81949_row17_col3\" class=\"data row17 col3\" >0.40 ['localizer', 'issue_analyzer', 'listener_core', 'project', 'change_suggester']</td>\n",
       "      <td id=\"T_81949_row17_col4\" class=\"data row17 col4\" >0.20 ['issue_analyzer', 'change_suggester', 'listener_core', 'localizer', 'project']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81949_level0_row18\" class=\"row_heading level0 row18\" >19</th>\n",
       "      <td id=\"T_81949_row18_col0\" class=\"data row18 col0\" >decide to respond to an issue</td>\n",
       "      <td id=\"T_81949_row18_col1\" class=\"data row18 col1\" >['listener_core', 'model_configuration_manager', 'localizer', 'project', 'api']</td>\n",
       "      <td id=\"T_81949_row18_col2\" class=\"data row18 col2\" >0.40 ['issue_analyzer', 'change_suggester', 'localizer', 'listener_core', 'file_analyzer']</td>\n",
       "      <td id=\"T_81949_row18_col3\" class=\"data row18 col3\" >0.60 ['localizer', 'api', 'listener_core', 'change_suggester', 'issue_analyzer']</td>\n",
       "      <td id=\"T_81949_row18_col4\" class=\"data row18 col4\" >0.60 ['change_suggester', 'issue_analyzer', 'listener_core', 'api', 'localizer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81949_level0_row19\" class=\"row_heading level0 row19\" >20</th>\n",
       "      <td id=\"T_81949_row19_col0\" class=\"data row19 col0\" >domain / project memories</td>\n",
       "      <td id=\"T_81949_row19_col1\" class=\"data row19 col1\" >['listener_core', 'model_configuration_manager', 'project', 'localizer', 'change_suggester']</td>\n",
       "      <td id=\"T_81949_row19_col2\" class=\"data row19 col2\" >0.40 ['change_suggester', 'issue_analyzer', 'localizer', 'file_analyzer', 'package_summary']</td>\n",
       "      <td id=\"T_81949_row19_col3\" class=\"data row19 col3\" >0.60 ['localizer', 'api', 'project', 'change_suggester', 'package_summary']</td>\n",
       "      <td id=\"T_81949_row19_col4\" class=\"data row19 col4\" >0.60 ['change_suggester', 'api', 'issue_analyzer', 'listener_core', 'localizer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81949_level0_row20\" class=\"row_heading level0 row20\" >21</th>\n",
       "      <td id=\"T_81949_row20_col0\" class=\"data row20 col0\" >memories api</td>\n",
       "      <td id=\"T_81949_row20_col1\" class=\"data row20 col1\" >['flask_server', 'lambda_function', 'project', 'listener_core']</td>\n",
       "      <td id=\"T_81949_row20_col2\" class=\"data row20 col2\" >0.25 ['listener_core', 'change_suggester', 'issue_analyzer', 'onboard_agent', 'project_manager']</td>\n",
       "      <td id=\"T_81949_row20_col3\" class=\"data row20 col3\" >0.50 ['project', 'listener_core', 'model_configuration_manager', 'localizer', 'project_manager']</td>\n",
       "      <td id=\"T_81949_row20_col4\" class=\"data row20 col4\" >0.50 ['listener_core', 'project', 'change_suggester', 'onboard_agent', 'project_manager']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81949_level0_row21\" class=\"row_heading level0 row21\" >22</th>\n",
       "      <td id=\"T_81949_row21_col0\" class=\"data row21 col0\" >proactive creation of package-detail document</td>\n",
       "      <td id=\"T_81949_row21_col1\" class=\"data row21 col1\" >['project']</td>\n",
       "      <td id=\"T_81949_row21_col2\" class=\"data row21 col2\" >0.00 ['package_summary', 'localizer', 'file_analyzer', 'change_suggester', 'issue_analyzer']</td>\n",
       "      <td id=\"T_81949_row21_col3\" class=\"data row21 col3\" >0.60 ['package_summary', 'localizer', 'project', 'file_analyzer', 'model_configuration_manager']</td>\n",
       "      <td id=\"T_81949_row21_col4\" class=\"data row21 col4\" >0.20 ['package_summary', 'localizer', 'change_suggester', 'file_analyzer', 'project']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81949_level0_row22\" class=\"row_heading level0 row22\" >23</th>\n",
       "      <td id=\"T_81949_row22_col0\" class=\"data row22 col0\" >proactive creation of package-detail document</td>\n",
       "      <td id=\"T_81949_row22_col1\" class=\"data row22 col1\" >['project', 'localizer', 'model_configuration_manager']</td>\n",
       "      <td id=\"T_81949_row22_col2\" class=\"data row22 col2\" >0.33 ['package_summary', 'localizer', 'file_analyzer', 'change_suggester', 'issue_analyzer']</td>\n",
       "      <td id=\"T_81949_row22_col3\" class=\"data row22 col3\" >0.87 ['package_summary', 'localizer', 'project', 'file_analyzer', 'model_configuration_manager']</td>\n",
       "      <td id=\"T_81949_row22_col4\" class=\"data row22 col4\" >0.53 ['package_summary', 'localizer', 'change_suggester', 'file_analyzer', 'project']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81949_level0_row23\" class=\"row_heading level0 row23\" >24</th>\n",
       "      <td id=\"T_81949_row23_col0\" class=\"data row23 col0\" >Total</td>\n",
       "      <td id=\"T_81949_row23_col1\" class=\"data row23 col1\" ></td>\n",
       "      <td id=\"T_81949_row23_col2\" class=\"data row23 col2\" >12.32</td>\n",
       "      <td id=\"T_81949_row23_col3\" class=\"data row23 col3\" >18.10</td>\n",
       "      <td id=\"T_81949_row23_col4\" class=\"data row23 col4\" >16.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x357093020>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a copy of the DataFrame for display purposes\n",
    "display_df = evaluation_results.copy()\n",
    "\n",
    "# Set the index to start from 1\n",
    "display_df.index = display_df.index + 1\n",
    "\n",
    "# Apply left alignment to all columns, including headers\n",
    "df_style = display_df.style \\\n",
    "    .set_table_attributes(\"style='width:100%'\") \\\n",
    "    .set_properties(**{'text-align': 'left'}) \\\n",
    "    .set_table_styles([{\n",
    "        'selector': 'th',\n",
    "        'props': [('text-align', 'left')]\n",
    "    }])\n",
    "\n",
    "df_style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleanup the temporary directory for combined files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(combined_docs_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
